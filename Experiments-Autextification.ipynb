{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbe3e8dd",
   "metadata": {},
   "source": [
    "### List of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ca443de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = { \"descriptive\": ['num_words', 'num_different_forms', 'num_different_forms_incidence',\n",
    "                                 'num_words_with_punct',\n",
    "                                 'num_paragraphs', 'num_paragraphs_incidence',\n",
    "                                 'num_sentences',\n",
    "                                 'num_sentences_incidence', 'sentences_per_paragraph_mean',\n",
    "                                 'sentences_per_paragraph_std',\n",
    "                                 'sentences_length_mean', 'sentences_length_std', 'sentences_length_no_stopwords_mean',\n",
    "                                 'sentences_length_no_stopwords_std', 'num_syllables_words_mean',\n",
    "                                 'num_syllables_words_std',\n",
    "                                 'words_length_mean', 'words_length_std', 'words_length_no_stopwords_mean',\n",
    "                                 'words_length_no_stopwords_std',\n",
    "                                 'lemmas_length_mean', 'lemmas_length_std'],\n",
    "        \"lexical_diversity\": ['lexical_density', 'noun_density', 'verb_density', 'adj_density', 'adv_density',\n",
    "                                      'simple_ttr', 'content_ttr', 'nttr', 'vttr', 'adj_ttr', 'adv_ttr', 'lemma_ttr',\n",
    "                                      'lemma_content_ttr', 'lemma_nttr', 'lemma_vttr', 'lemma_adj_ttr', 'lemma_adv_ttr',\n",
    "                                      'honore', 'maas', 'mtld'],\n",
    "        \"readability\": ['flesch', 'smog'],\n",
    "        \"word_frequency\": ['min_wf_per_sentence', 'num_rare_nouns', 'num_rare_nouns_incidence', 'num_rare_adj',\n",
    "                                   'num_rare_adj_incidence', 'num_rare_verbs', 'num_rare_verbs_incidence',\n",
    "                                   'num_rare_advb',\n",
    "                                   'num_rare_advb_incidence', 'num_rare_words', 'num_rare_words_incidence',\n",
    "                                   'num_dif_rare_words',\n",
    "                                   'num_dif_rare_words_incidence', 'mean_rare', 'mean_distinct_rare'],\n",
    "        \"vocabulary_knowledge\": ['num_a1_words', 'num_a1_words_incidence', 'num_a2_words',\n",
    "                                         'num_a2_words_incidence',\n",
    "                                         'num_b1_words', 'num_b1_words_incidence', 'num_b2_words',\n",
    "                                         'num_b2_words_incidence',\n",
    "                                         'num_c1_words', 'num_c1_words_incidence', 'num_content_words_not_a1_c1_words',\n",
    "                                         'num_content_words_not_a1_c1_words_incidence'],\n",
    "        \"word_information\": ['num_lexic_words', 'num_lexic_words_incidence', 'num_noun', 'num_noun_incidence',\n",
    "                                     'num_proper_noun', 'num_proper_noun_incidence', 'ratio_proper_nouns_per_nouns',\n",
    "                                     'num_adj', 'num_adj_incidence', 'num_adv', 'num_adv_incidence', 'num_verb',\n",
    "                                     'num_verb_incidence', 'num_past', 'num_past_incidence', 'num_pres',\n",
    "                                     'num_pres_incidence',\n",
    "                                     'num_future', 'num_future_incidence', 'num_indic', 'num_indic_incidence',\n",
    "                                     'num_impera',\n",
    "                                     'num_impera_incidence', 'num_past_irregular', 'num_past_irregular_incidence',\n",
    "                                     'num_past_irregular_mean', 'num_personal_pronouns',\n",
    "                                     'num_personal_pronouns_incidence',\n",
    "                                     'num_first_pers_pron', 'num_first_pers_pron_incidence', 'num_first_pers_sing_pron',\n",
    "                                     'num_first_pers_sing_pron_incidence', 'num_third_pers_pron',\n",
    "                                     'num_third_pers_pron_incidence'],\n",
    "        \"syntactic_complexity\": ['left_embeddedness', 'num_decendents_noun_phrase', 'num_modifiers_noun_phrase',\n",
    "                                         'mean_depth_per_sentence', 'num_subord', 'num_subord_incidence',\n",
    "                                         'num_rel_subord', 'num_rel_subord_incidence', 'num_punct_marks_per_sentence',\n",
    "                                         'num_total_prop', 'mean_propositions_per_sentence', 'mean_vp_per_sentence',\n",
    "                                         'mean_np_per_sentence', 'noun_phrase_density_incidence',\n",
    "                                         'verb_phrase_density_incidence',\n",
    "                                         'num_pass', 'num_pass_incidence', 'num_pass_mean', 'num_agentless',\n",
    "                                         'agentless_passive_incidence', 'num_neg', 'negation_incidence',\n",
    "                                         'num_ger', 'gerund_incidence', 'num_inf', 'infinitive_incidence'],\n",
    "        \"word_semantic_information\": ['polysemic_index', 'hypernymy_verbs_index', 'hypernymy_nouns_index',\n",
    "                                             'hypernymy_index'],\n",
    "        \"referential_cohesion\": ['noun_overlap_adjacent', 'noun_overlap_all', 'argument_overlap_adjacent',\n",
    "                                         'argument_overlap_all', 'stem_overlap_adjacent', 'stem_overlap_all',\n",
    "                                         'content_overlap_adjacent_mean', 'content_overlap_adjacent_std',\n",
    "                                         'content_overlap_all_mean', 'content_overlap_all_std'],\n",
    "        \"semantic_overlap\": ['similarity_adjacent_mean', 'similarity_pairs_par_mean',\n",
    "                                     'similarity_adjacent_par_mean',\n",
    "                                     'similarity_adjacent_std', 'similarity_pairs_par_std',\n",
    "                                     'similarity_adjacent_par_std'],\n",
    "        \"discourse_connectives\": ['all_connectives', 'all_connectives_incidence', 'causal_connectives',\n",
    "                                          'causal_connectives_incidence',\n",
    "                                          'logical_connectives', 'logical_connectives_incidence',\n",
    "                                          'adversative_connectives',\n",
    "                                          'adversative_connectives_incidence', 'temporal_connectives',\n",
    "                                          'temporal_connectives_incidence',\n",
    "                                          'conditional_connectives', 'conditional_connectives_incidence']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77f0c11",
   "metadata": {},
   "source": [
    "### Loading report and label paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "47f2ad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"subtask_1/es/report.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c98f6464",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = \"subtask_1/es/train.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a3308c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0d8ed31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(path, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8d1d4e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label_train = pd.read_csv(label_path, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2a4bc7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5464</td>\n",
       "      <td>Entrada en vigor. La presente Directiva entrar...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30129</td>\n",
       "      <td>Preguntas: 1. ¿Cuáles son los principales argu...</td>\n",
       "      <td>generated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19553</td>\n",
       "      <td>¿Desea algo? Póngame una caja de madera. ¿Qué ...</td>\n",
       "      <td>generated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13005</td>\n",
       "      <td>@victor28088 1665 Tweets no originales, que as...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16919</td>\n",
       "      <td>De pequeño Dios me dio a elegir entre tener un...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text      label\n",
       "0   5464  Entrada en vigor. La presente Directiva entrar...      human\n",
       "1  30129  Preguntas: 1. ¿Cuáles son los principales argu...  generated\n",
       "2  19553  ¿Desea algo? Póngame una caja de madera. ¿Qué ...  generated\n",
       "3  13005  @victor28088 1665 Tweets no originales, que as...      human\n",
       "4  16919  De pequeño Dios me dio a elegir entre tener un...      human"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "32ebc6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adj_density</th>\n",
       "      <th>adj_ttr</th>\n",
       "      <th>adv_density</th>\n",
       "      <th>adv_ttr</th>\n",
       "      <th>adversative_connectives</th>\n",
       "      <th>adversative_connectives_incidence</th>\n",
       "      <th>all_connectives</th>\n",
       "      <th>all_connectives_incidence</th>\n",
       "      <th>argument_overlap_adjacent</th>\n",
       "      <th>argument_overlap_all</th>\n",
       "      <th>...</th>\n",
       "      <th>stem_overlap_all</th>\n",
       "      <th>temporal_connectives</th>\n",
       "      <th>temporal_connectives_incidence</th>\n",
       "      <th>verb_density</th>\n",
       "      <th>verb_phrase_density_incidence</th>\n",
       "      <th>vttr</th>\n",
       "      <th>words_length_mean</th>\n",
       "      <th>words_length_no_stopwords_mean</th>\n",
       "      <th>words_length_no_stopwords_std</th>\n",
       "      <th>words_length_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0682</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>45.4545</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.9756</td>\n",
       "      <td>7.7895</td>\n",
       "      <td>2.4188</td>\n",
       "      <td>3.2119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0143</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>42.8571</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0429</td>\n",
       "      <td>42.8571</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.6615</td>\n",
       "      <td>8.2800</td>\n",
       "      <td>2.7498</td>\n",
       "      <td>3.4431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>250.0000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.8333</td>\n",
       "      <td>6.0000</td>\n",
       "      <td>1.1952</td>\n",
       "      <td>1.7240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1176</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1176</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2941</td>\n",
       "      <td>294.1176</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.3750</td>\n",
       "      <td>6.5714</td>\n",
       "      <td>2.9207</td>\n",
       "      <td>2.8257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1304</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.4783</td>\n",
       "      <td>2.0</td>\n",
       "      <td>86.9565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2174</td>\n",
       "      <td>217.3913</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.9130</td>\n",
       "      <td>6.1250</td>\n",
       "      <td>1.6154</td>\n",
       "      <td>2.3015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32057</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.6316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2632</td>\n",
       "      <td>263.1579</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>5.2857</td>\n",
       "      <td>2.5475</td>\n",
       "      <td>2.2669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32058</th>\n",
       "      <td>0.0909</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.0227</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.7273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0682</td>\n",
       "      <td>68.1818</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.4211</td>\n",
       "      <td>8.3529</td>\n",
       "      <td>1.7130</td>\n",
       "      <td>3.1173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32059</th>\n",
       "      <td>0.1364</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>90.9091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1818</td>\n",
       "      <td>181.8182</td>\n",
       "      <td>0.75</td>\n",
       "      <td>4.3636</td>\n",
       "      <td>6.7500</td>\n",
       "      <td>3.0721</td>\n",
       "      <td>2.8532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32060</th>\n",
       "      <td>0.0290</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>43.4783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0580</td>\n",
       "      <td>57.9710</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.5000</td>\n",
       "      <td>6.3333</td>\n",
       "      <td>2.6477</td>\n",
       "      <td>2.8156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32061</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.8235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.8235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1765</td>\n",
       "      <td>176.4706</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>6.6667</td>\n",
       "      <td>2.2111</td>\n",
       "      <td>2.4495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32062 rows × 141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       adj_density  adj_ttr  adv_density  adv_ttr  adversative_connectives  \\\n",
       "0           0.0682   0.6667       0.0000      0.0                      0.0   \n",
       "1           0.0143   1.0000       0.0000      0.0                      0.0   \n",
       "2           0.0000   0.0000       0.0000      0.0                      0.0   \n",
       "3           0.1176   1.0000       0.1176      0.5                      0.0   \n",
       "4           0.1304   1.0000       0.0435      1.0                      1.0   \n",
       "...            ...      ...          ...      ...                      ...   \n",
       "32057       0.0000   0.0000       0.0526      1.0                      0.0   \n",
       "32058       0.0909   0.7500       0.0227      1.0                      0.0   \n",
       "32059       0.1364   1.0000       0.0000      0.0                      0.0   \n",
       "32060       0.0290   1.0000       0.0000      0.0                      0.0   \n",
       "32061       0.0000   0.0000       0.0588      1.0                      1.0   \n",
       "\n",
       "       adversative_connectives_incidence  all_connectives  \\\n",
       "0                                 0.0000              0.0   \n",
       "1                                 0.0000              3.0   \n",
       "2                                 0.0000              0.0   \n",
       "3                                 0.0000              0.0   \n",
       "4                                43.4783              2.0   \n",
       "...                                  ...              ...   \n",
       "32057                             0.0000              1.0   \n",
       "32058                             0.0000              1.0   \n",
       "32059                             0.0000              2.0   \n",
       "32060                             0.0000              3.0   \n",
       "32061                            58.8235              1.0   \n",
       "\n",
       "       all_connectives_incidence  argument_overlap_adjacent  \\\n",
       "0                         0.0000                        0.4   \n",
       "1                        42.8571                        0.8   \n",
       "2                         0.0000                        0.0   \n",
       "3                         0.0000                        0.0   \n",
       "4                        86.9565                        0.0   \n",
       "...                          ...                        ...   \n",
       "32057                    52.6316                        0.0   \n",
       "32058                    22.7273                        0.0   \n",
       "32059                    90.9091                        0.0   \n",
       "32060                    43.4783                        0.0   \n",
       "32061                    58.8235                        0.0   \n",
       "\n",
       "       argument_overlap_all  ...  stem_overlap_all  temporal_connectives  \\\n",
       "0                    0.1333  ...            0.1333                   0.0   \n",
       "1                    0.6667  ...            0.6667                   0.0   \n",
       "2                    0.0000  ...            0.0000                   0.0   \n",
       "3                    0.0000  ...            0.0000                   0.0   \n",
       "4                    0.0000  ...            0.0000                   0.0   \n",
       "...                     ...  ...               ...                   ...   \n",
       "32057                0.0000  ...            0.0000                   0.0   \n",
       "32058                0.1333  ...            0.1333                   0.0   \n",
       "32059                0.0000  ...            0.0000                   0.0   \n",
       "32060                0.0000  ...            0.0000                   0.0   \n",
       "32061                0.0000  ...            0.0000                   0.0   \n",
       "\n",
       "       temporal_connectives_incidence  verb_density  \\\n",
       "0                                 0.0        0.0455   \n",
       "1                                 0.0        0.0429   \n",
       "2                                 0.0        0.2500   \n",
       "3                                 0.0        0.2941   \n",
       "4                                 0.0        0.2174   \n",
       "...                               ...           ...   \n",
       "32057                             0.0        0.2632   \n",
       "32058                             0.0        0.0682   \n",
       "32059                             0.0        0.1818   \n",
       "32060                             0.0        0.0580   \n",
       "32061                             0.0        0.1765   \n",
       "\n",
       "       verb_phrase_density_incidence  vttr  words_length_mean  \\\n",
       "0                            45.4545  1.00             4.9756   \n",
       "1                            42.8571  1.00             4.6615   \n",
       "2                           250.0000  1.00             4.8333   \n",
       "3                           294.1176  1.00             4.3750   \n",
       "4                           217.3913  1.00             3.9130   \n",
       "...                              ...   ...                ...   \n",
       "32057                       263.1579  1.00             3.5000   \n",
       "32058                        68.1818  1.00             5.4211   \n",
       "32059                       181.8182  0.75             4.3636   \n",
       "32060                        57.9710  1.00             4.5000   \n",
       "32061                       176.4706  1.00             4.0000   \n",
       "\n",
       "       words_length_no_stopwords_mean  words_length_no_stopwords_std  \\\n",
       "0                              7.7895                         2.4188   \n",
       "1                              8.2800                         2.7498   \n",
       "2                              6.0000                         1.1952   \n",
       "3                              6.5714                         2.9207   \n",
       "4                              6.1250                         1.6154   \n",
       "...                               ...                            ...   \n",
       "32057                          5.2857                         2.5475   \n",
       "32058                          8.3529                         1.7130   \n",
       "32059                          6.7500                         3.0721   \n",
       "32060                          6.3333                         2.6477   \n",
       "32061                          6.6667                         2.2111   \n",
       "\n",
       "       words_length_std  \n",
       "0                3.2119  \n",
       "1                3.4431  \n",
       "2                1.7240  \n",
       "3                2.8257  \n",
       "4                2.3015  \n",
       "...                 ...  \n",
       "32057            2.2669  \n",
       "32058            3.1173  \n",
       "32059            2.8532  \n",
       "32060            2.8156  \n",
       "32061            2.4495  \n",
       "\n",
       "[32062 rows x 141 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa1c505",
   "metadata": {},
   "source": [
    "### Replacing nan cells "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4cd29648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['flesch']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns[df_train.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "da93a45f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.522153\n",
       "1    0.158109\n",
       "2   -0.714475\n",
       "3   -0.002071\n",
       "4    0.043384\n",
       "Name: flesch, dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['flesch'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c05849e",
   "metadata": {},
   "source": [
    "#### Imputing using the mean as flesch is a continue variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9bd05d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a787ac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "52e03815",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['flesch'] = imp.fit_transform(df_train['flesch'].values.reshape(-1,1)).reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241c9390",
   "metadata": {},
   "source": [
    "### Scaling the variables (only the ones that contains values greater than 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e1e72d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cc3e690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = []\n",
    "column_idxs = []\n",
    "for idx, col in enumerate(df_train.columns):\n",
    "    if df_train[col].max() > 1:\n",
    "        column_idxs.append(idx)\n",
    "        column_names.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ef92e11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adversative_connectives', 'adversative_connectives_incidence', 'all_connectives', 'all_connectives_incidence', 'causal_connectives', 'causal_connectives_incidence', 'conditional_connectives', 'conditional_connectives_incidence', 'flesch', 'gerund_incidence', 'honore', 'hypernymy_index', 'hypernymy_nouns_index', 'hypernymy_verbs_index', 'infinitive_incidence', 'left_embeddedness', 'lemma_ttr', 'lemmas_length_mean', 'lemmas_length_std', 'logical_connectives', 'logical_connectives_incidence', 'maas', 'mean_depth_per_sentence', 'mean_distinct_rare', 'mean_np_per_sentence', 'mean_propositions_per_sentence', 'mean_rare', 'mean_vp_per_sentence', 'min_wf_per_sentence', 'mtld', 'negation_incidence', 'noun_phrase_density_incidence', 'num_adj', 'num_adj_incidence', 'num_adv', 'num_adv_incidence', 'num_decendents_noun_phrase', 'num_dif_rare_words', 'num_dif_rare_words_incidence', 'num_different_forms', 'num_different_forms_incidence', 'num_first_pers_pron', 'num_first_pers_pron_incidence', 'num_first_pers_sing_pron', 'num_first_pers_sing_pron_incidence', 'num_ger', 'num_impera', 'num_impera_incidence', 'num_indic', 'num_indic_incidence', 'num_inf', 'num_lexic_words', 'num_lexic_words_incidence', 'num_modifiers_noun_phrase', 'num_neg', 'num_noun', 'num_noun_incidence', 'num_paragraphs', 'num_paragraphs_incidence', 'num_past', 'num_past_incidence', 'num_past_irregular', 'num_past_irregular_incidence', 'num_personal_pronouns', 'num_personal_pronouns_incidence', 'num_pres', 'num_pres_incidence', 'num_proper_noun', 'num_proper_noun_incidence', 'num_punct_marks_per_sentence', 'num_rare_adj', 'num_rare_adj_incidence', 'num_rare_advb', 'num_rare_advb_incidence', 'num_rare_nouns', 'num_rare_nouns_incidence', 'num_rare_verbs', 'num_rare_verbs_incidence', 'num_rare_words', 'num_rare_words_incidence', 'num_sentences', 'num_sentences_incidence', 'num_subord', 'num_subord_incidence', 'num_syllables_words_mean', 'num_syllables_words_std', 'num_third_pers_pron', 'num_third_pers_pron_incidence', 'num_total_prop', 'num_verb', 'num_verb_incidence', 'num_words', 'num_words_with_punct', 'polysemic_index', 'sentences_length_mean', 'sentences_length_no_stopwords_mean', 'sentences_length_no_stopwords_std', 'sentences_length_std', 'sentences_per_paragraph_mean', 'sentences_per_paragraph_std', 'simple_ttr', 'temporal_connectives', 'temporal_connectives_incidence', 'verb_phrase_density_incidence', 'words_length_mean', 'words_length_no_stopwords_mean', 'words_length_no_stopwords_std', 'words_length_std']\n"
     ]
    }
   ],
   "source": [
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "055f5bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer([(\"standard_scaler\", StandardScaler(), column_idxs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "63024d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ct.fit_transform(df_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e6f9fc25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32062, 108)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4d4e8354",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[column_names] = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "21484646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adj_density</th>\n",
       "      <th>adj_ttr</th>\n",
       "      <th>adv_density</th>\n",
       "      <th>adv_ttr</th>\n",
       "      <th>adversative_connectives</th>\n",
       "      <th>adversative_connectives_incidence</th>\n",
       "      <th>all_connectives</th>\n",
       "      <th>all_connectives_incidence</th>\n",
       "      <th>argument_overlap_adjacent</th>\n",
       "      <th>argument_overlap_all</th>\n",
       "      <th>...</th>\n",
       "      <th>stem_overlap_all</th>\n",
       "      <th>temporal_connectives</th>\n",
       "      <th>temporal_connectives_incidence</th>\n",
       "      <th>verb_density</th>\n",
       "      <th>verb_phrase_density_incidence</th>\n",
       "      <th>vttr</th>\n",
       "      <th>words_length_mean</th>\n",
       "      <th>words_length_no_stopwords_mean</th>\n",
       "      <th>words_length_no_stopwords_std</th>\n",
       "      <th>words_length_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0682</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.618748</td>\n",
       "      <td>-0.514903</td>\n",
       "      <td>-1.155472</td>\n",
       "      <td>-1.384126</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>-0.546647</td>\n",
       "      <td>-0.512815</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>-1.243655</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.478914</td>\n",
       "      <td>0.547375</td>\n",
       "      <td>0.361112</td>\n",
       "      <td>0.606354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0143</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.618748</td>\n",
       "      <td>-0.514903</td>\n",
       "      <td>-0.322293</td>\n",
       "      <td>-0.617192</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>-0.546647</td>\n",
       "      <td>-0.512815</td>\n",
       "      <td>0.0429</td>\n",
       "      <td>-1.278517</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.015662</td>\n",
       "      <td>0.977367</td>\n",
       "      <td>0.817672</td>\n",
       "      <td>0.954612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.618748</td>\n",
       "      <td>-0.514903</td>\n",
       "      <td>-1.155472</td>\n",
       "      <td>-1.384126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.546647</td>\n",
       "      <td>-0.512815</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>1.501729</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.269042</td>\n",
       "      <td>-1.021370</td>\n",
       "      <td>-1.326643</td>\n",
       "      <td>-1.634876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1176</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1176</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.618748</td>\n",
       "      <td>-0.514903</td>\n",
       "      <td>-1.155472</td>\n",
       "      <td>-1.384126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.546647</td>\n",
       "      <td>-0.512815</td>\n",
       "      <td>0.2941</td>\n",
       "      <td>2.093870</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.406885</td>\n",
       "      <td>-0.520458</td>\n",
       "      <td>1.053401</td>\n",
       "      <td>0.024619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1304</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.277493</td>\n",
       "      <td>1.165838</td>\n",
       "      <td>-0.600020</td>\n",
       "      <td>0.171972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.546647</td>\n",
       "      <td>-0.512815</td>\n",
       "      <td>0.2174</td>\n",
       "      <td>1.064059</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-1.088270</td>\n",
       "      <td>-0.911790</td>\n",
       "      <td>-0.747046</td>\n",
       "      <td>-0.764985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32057</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.618748</td>\n",
       "      <td>-0.514903</td>\n",
       "      <td>-0.877746</td>\n",
       "      <td>-0.442276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.546647</td>\n",
       "      <td>-0.512815</td>\n",
       "      <td>0.2632</td>\n",
       "      <td>1.678333</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-1.697386</td>\n",
       "      <td>-1.647553</td>\n",
       "      <td>0.538633</td>\n",
       "      <td>-0.817104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32058</th>\n",
       "      <td>0.0909</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.0227</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.618748</td>\n",
       "      <td>-0.514903</td>\n",
       "      <td>-0.877746</td>\n",
       "      <td>-0.977418</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>-0.546647</td>\n",
       "      <td>-0.512815</td>\n",
       "      <td>0.0682</td>\n",
       "      <td>-0.938612</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.135964</td>\n",
       "      <td>1.041274</td>\n",
       "      <td>-0.612423</td>\n",
       "      <td>0.463858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32059</th>\n",
       "      <td>0.1364</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.618748</td>\n",
       "      <td>-0.514903</td>\n",
       "      <td>-0.600020</td>\n",
       "      <td>0.242705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.546647</td>\n",
       "      <td>-0.512815</td>\n",
       "      <td>0.1818</td>\n",
       "      <td>0.586601</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.423699</td>\n",
       "      <td>-0.363891</td>\n",
       "      <td>1.262232</td>\n",
       "      <td>0.066043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32060</th>\n",
       "      <td>0.0290</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.618748</td>\n",
       "      <td>-0.514903</td>\n",
       "      <td>-0.322293</td>\n",
       "      <td>-0.606076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.546647</td>\n",
       "      <td>-0.512815</td>\n",
       "      <td>0.0580</td>\n",
       "      <td>-1.075660</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.222528</td>\n",
       "      <td>-0.729186</td>\n",
       "      <td>0.676842</td>\n",
       "      <td>0.009406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32061</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.277493</td>\n",
       "      <td>1.759038</td>\n",
       "      <td>-0.877746</td>\n",
       "      <td>-0.331472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.546647</td>\n",
       "      <td>-0.512815</td>\n",
       "      <td>0.1765</td>\n",
       "      <td>0.514827</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.959957</td>\n",
       "      <td>-0.436915</td>\n",
       "      <td>0.074624</td>\n",
       "      <td>-0.542052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32062 rows × 141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       adj_density  adj_ttr  adv_density  adv_ttr  adversative_connectives  \\\n",
       "0           0.0682   0.6667       0.0000      0.0                -0.618748   \n",
       "1           0.0143   1.0000       0.0000      0.0                -0.618748   \n",
       "2           0.0000   0.0000       0.0000      0.0                -0.618748   \n",
       "3           0.1176   1.0000       0.1176      0.5                -0.618748   \n",
       "4           0.1304   1.0000       0.0435      1.0                 0.277493   \n",
       "...            ...      ...          ...      ...                      ...   \n",
       "32057       0.0000   0.0000       0.0526      1.0                -0.618748   \n",
       "32058       0.0909   0.7500       0.0227      1.0                -0.618748   \n",
       "32059       0.1364   1.0000       0.0000      0.0                -0.618748   \n",
       "32060       0.0290   1.0000       0.0000      0.0                -0.618748   \n",
       "32061       0.0000   0.0000       0.0588      1.0                 0.277493   \n",
       "\n",
       "       adversative_connectives_incidence  all_connectives  \\\n",
       "0                              -0.514903        -1.155472   \n",
       "1                              -0.514903        -0.322293   \n",
       "2                              -0.514903        -1.155472   \n",
       "3                              -0.514903        -1.155472   \n",
       "4                               1.165838        -0.600020   \n",
       "...                                  ...              ...   \n",
       "32057                          -0.514903        -0.877746   \n",
       "32058                          -0.514903        -0.877746   \n",
       "32059                          -0.514903        -0.600020   \n",
       "32060                          -0.514903        -0.322293   \n",
       "32061                           1.759038        -0.877746   \n",
       "\n",
       "       all_connectives_incidence  argument_overlap_adjacent  \\\n",
       "0                      -1.384126                        0.4   \n",
       "1                      -0.617192                        0.8   \n",
       "2                      -1.384126                        0.0   \n",
       "3                      -1.384126                        0.0   \n",
       "4                       0.171972                        0.0   \n",
       "...                          ...                        ...   \n",
       "32057                  -0.442276                        0.0   \n",
       "32058                  -0.977418                        0.0   \n",
       "32059                   0.242705                        0.0   \n",
       "32060                  -0.606076                        0.0   \n",
       "32061                  -0.331472                        0.0   \n",
       "\n",
       "       argument_overlap_all  ...  stem_overlap_all  temporal_connectives  \\\n",
       "0                    0.1333  ...            0.1333             -0.546647   \n",
       "1                    0.6667  ...            0.6667             -0.546647   \n",
       "2                    0.0000  ...            0.0000             -0.546647   \n",
       "3                    0.0000  ...            0.0000             -0.546647   \n",
       "4                    0.0000  ...            0.0000             -0.546647   \n",
       "...                     ...  ...               ...                   ...   \n",
       "32057                0.0000  ...            0.0000             -0.546647   \n",
       "32058                0.1333  ...            0.1333             -0.546647   \n",
       "32059                0.0000  ...            0.0000             -0.546647   \n",
       "32060                0.0000  ...            0.0000             -0.546647   \n",
       "32061                0.0000  ...            0.0000             -0.546647   \n",
       "\n",
       "       temporal_connectives_incidence  verb_density  \\\n",
       "0                           -0.512815        0.0455   \n",
       "1                           -0.512815        0.0429   \n",
       "2                           -0.512815        0.2500   \n",
       "3                           -0.512815        0.2941   \n",
       "4                           -0.512815        0.2174   \n",
       "...                               ...           ...   \n",
       "32057                       -0.512815        0.2632   \n",
       "32058                       -0.512815        0.0682   \n",
       "32059                       -0.512815        0.1818   \n",
       "32060                       -0.512815        0.0580   \n",
       "32061                       -0.512815        0.1765   \n",
       "\n",
       "       verb_phrase_density_incidence  vttr  words_length_mean  \\\n",
       "0                          -1.243655  1.00           0.478914   \n",
       "1                          -1.278517  1.00           0.015662   \n",
       "2                           1.501729  1.00           0.269042   \n",
       "3                           2.093870  1.00          -0.406885   \n",
       "4                           1.064059  1.00          -1.088270   \n",
       "...                              ...   ...                ...   \n",
       "32057                       1.678333  1.00          -1.697386   \n",
       "32058                      -0.938612  1.00           1.135964   \n",
       "32059                       0.586601  0.75          -0.423699   \n",
       "32060                      -1.075660  1.00          -0.222528   \n",
       "32061                       0.514827  1.00          -0.959957   \n",
       "\n",
       "       words_length_no_stopwords_mean  words_length_no_stopwords_std  \\\n",
       "0                            0.547375                       0.361112   \n",
       "1                            0.977367                       0.817672   \n",
       "2                           -1.021370                      -1.326643   \n",
       "3                           -0.520458                       1.053401   \n",
       "4                           -0.911790                      -0.747046   \n",
       "...                               ...                            ...   \n",
       "32057                       -1.647553                       0.538633   \n",
       "32058                        1.041274                      -0.612423   \n",
       "32059                       -0.363891                       1.262232   \n",
       "32060                       -0.729186                       0.676842   \n",
       "32061                       -0.436915                       0.074624   \n",
       "\n",
       "       words_length_std  \n",
       "0              0.606354  \n",
       "1              0.954612  \n",
       "2             -1.634876  \n",
       "3              0.024619  \n",
       "4             -0.764985  \n",
       "...                 ...  \n",
       "32057         -0.817104  \n",
       "32058          0.463858  \n",
       "32059          0.066043  \n",
       "32060          0.009406  \n",
       "32061         -0.542052  \n",
       "\n",
       "[32062 rows x 141 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9951a1dd",
   "metadata": {},
   "source": [
    "#### in the case all are processed together (DON'T USE IT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1bddbcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d8fae9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaler.fit_transform(df_train)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ebbbe38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32062, 141)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41dc137",
   "metadata": {},
   "source": [
    "### Getting input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f1b89920",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.values\n",
    "y = df_label_train[\"label\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563774dc",
   "metadata": {},
   "source": [
    "### Simple Training (just dummy tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2991dcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a852a384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "#clf = svm.SVC(kernel='linear', C=1, random_state=42)\n",
    "clf = tree.DecisionTreeClassifier(min_samples_split=20)\n",
    "scores = cross_val_score(clf, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2916ba1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72945579, 0.73538126, 0.73222084, 0.73253275, 0.73658765])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3525c220",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "scores = cross_val_score(clf, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b7341c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72711679, 0.73865586, 0.73097318, 0.72988147, 0.73003743])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f75ba59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "949ef697",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=50, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "712ca832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82020895, 0.81662249, 0.81674984, 0.81550218, 0.81363069])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db17a6f",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fb5561f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: (&#x27;gini&#x27;, &#x27;entropy&#x27;),\n",
       "                         &#x27;max_depth&#x27;: [5, 10, 15, 20, 25],\n",
       "                         &#x27;min_samples_split&#x27;: [10, 15, 20, 25, 30, 35, 40],\n",
       "                         &#x27;n_estimators&#x27;: [25, 50, 75, 100, 125]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: (&#x27;gini&#x27;, &#x27;entropy&#x27;),\n",
       "                         &#x27;max_depth&#x27;: [5, 10, 15, 20, 25],\n",
       "                         &#x27;min_samples_split&#x27;: [10, 15, 20, 25, 30, 35, 40],\n",
       "                         &#x27;n_estimators&#x27;: [25, 50, 75, 100, 125]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'criterion': ('gini', 'entropy'),\n",
       "                         'max_depth': [5, 10, 15, 20, 25],\n",
       "                         'min_samples_split': [10, 15, 20, 25, 30, 35, 40],\n",
       "                         'n_estimators': [25, 50, 75, 100, 125]})"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'n_estimators': [25, 50, 75, 100, 125],\n",
    "              'criterion':('gini', 'entropy'),\n",
    "              'max_depth':[5,10,15,20,25],\n",
    "              'min_samples_split': [10, 15, 20, 25, 30, 35, 40]}\n",
    "random_forest = RandomForestClassifier()\n",
    "clf = GridSearchCV(random_forest, parameters, cv=5)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c238f05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 10, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d6d21076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8219385159920114\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "338de0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([ 1.56724062,  2.1272254 ,  3.07088723,  4.24263949,  4.95359621,\n",
      "        1.07306619,  2.09322267,  2.82034106,  4.23325524,  5.02711921,\n",
      "        0.94218435,  1.94373169,  3.09192505,  4.12668138,  5.04043827,\n",
      "        1.02766142,  1.98258724,  2.71509581,  3.54288807,  5.007971  ,\n",
      "        1.12783861,  2.24779124,  3.39343863,  4.0783884 ,  4.59097815,\n",
      "        0.91623411,  1.78618045,  2.71326113,  3.55787292,  4.58358788,\n",
      "        1.08747149,  2.22975221,  3.36767473,  3.80811291,  4.91705513,\n",
      "        1.77919459,  3.54218998,  5.03049092,  6.75450315,  9.31769204,\n",
      "        2.19971757,  3.98587842,  5.14356279,  8.38932195,  8.57852716,\n",
      "        1.65348239,  3.23670616,  4.82050519,  6.46751332,  8.12683539,\n",
      "        1.63500328,  3.23564839,  4.8450551 ,  6.42822971,  8.0150918 ,\n",
      "        1.59771914,  3.23923707,  4.78604584,  6.36517806,  7.98128867,\n",
      "        1.6004477 ,  3.16778598,  4.76238289,  6.32137938,  7.88756428,\n",
      "        1.59478407,  3.16904554,  4.74898429,  6.28673539,  7.87213173,\n",
      "        2.14788432,  4.26991282,  6.42773061,  8.52335968, 10.69258132,\n",
      "        2.14124932,  4.22812328,  6.33231564,  8.46495004, 10.53849936,\n",
      "        2.10251083,  4.20291204,  6.3341382 ,  8.35032086, 10.49021764,\n",
      "        2.08497672,  4.1335547 ,  6.21278996,  8.27639127, 10.75772099,\n",
      "        2.50285392,  4.44276953,  6.23718104,  9.03781905, 11.05617142,\n",
      "        2.57075782,  6.39306779,  9.99687729, 12.00660558, 17.0504981 ,\n",
      "        3.50935559,  6.75760841, 10.100881  , 13.32977123, 16.0262722 ,\n",
      "        3.75518618,  7.49934235, 11.16231942, 15.09221549, 18.86158657,\n",
      "        3.77400737,  7.42114778, 11.16216044, 14.92611189, 18.5304719 ,\n",
      "        3.75788288,  7.29686937, 10.95272813, 14.58301444, 18.47417941,\n",
      "        3.58211784,  7.14484916, 10.82666297, 14.63408561, 17.80167522,\n",
      "        3.5714479 ,  7.1620656 , 10.54998732, 14.13707457, 17.61618299,\n",
      "        3.3937398 ,  7.18220463, 10.70784383, 14.24704823, 12.98126225,\n",
      "        2.22872272,  4.56627336,  6.92009754,  9.39461966, 11.93994741,\n",
      "        2.65079865,  5.45814266,  8.01882896,  9.99765248, 12.71120429,\n",
      "        2.61779242,  5.47581229,  8.14464798, 10.27852778, 12.15643005,\n",
      "        2.41197057,  4.81342778,  7.20918579,  9.59232655, 12.05255132,\n",
      "        2.3932519 ,  4.75336881,  7.12825847,  9.42077975, 11.82394681,\n",
      "        2.34909863,  4.6754395 ,  6.99866276,  9.35780048, 11.7023675 ,\n",
      "        2.30741372,  4.62613101,  6.90655289,  9.19374003, 11.49967728,\n",
      "        2.28165936,  4.55742908,  6.83374557,  9.13881292, 11.35741024,\n",
      "        0.9627131 ,  1.90246406,  2.82648721,  3.82120967,  4.75989523,\n",
      "        0.96676993,  1.9157208 ,  2.85645981,  3.81377759,  4.76083636,\n",
      "        0.97114959,  1.94028788,  2.86651611,  3.80990682,  4.74365849,\n",
      "        0.96875587,  1.90403771,  2.86864486,  3.79319763,  4.74775891,\n",
      "        0.96924276,  1.90005374,  2.87174273,  3.80399375,  4.77668185,\n",
      "        0.97924948,  1.9253305 ,  2.85390487,  3.80792046,  4.76542497,\n",
      "        0.962674  ,  1.92126431,  2.87765222,  3.78305869,  4.75063968,\n",
      "        1.80008607,  3.5950696 ,  5.347931  ,  7.14849663,  9.00971732,\n",
      "        1.8078217 ,  3.58070784,  5.35202689,  7.116085  ,  8.91338797,\n",
      "        1.79082994,  3.54588332,  5.34213967,  7.09894776,  8.87608347,\n",
      "        1.78846378,  3.55899754,  5.31449518,  7.09329996,  8.86968369,\n",
      "        1.77155633,  3.5458302 ,  5.30191655,  7.07623539,  8.81845775,\n",
      "        1.79431343,  3.53231635,  5.28148074,  7.02619953,  8.81917973,\n",
      "        1.76749573,  3.5436121 ,  5.32580442,  7.02103758,  8.78453693,\n",
      "        2.38411007,  4.74501481,  7.1187068 ,  9.47822595, 11.86370244,\n",
      "        2.40360994,  4.723383  ,  7.04554639,  9.40302491, 11.74094281,\n",
      "        2.33874679,  4.65110402,  6.98401041,  9.29642358, 11.64058433,\n",
      "        2.31782999,  4.6081357 ,  6.92325706,  9.21634626, 11.49690218,\n",
      "        2.29706893,  4.58524776,  6.83452592,  9.14162383, 11.37321877,\n",
      "        2.26699753,  4.51345501,  6.80020437,  9.06643262, 11.66862149,\n",
      "        2.33734145,  4.64052887,  7.01637459,  9.21782427, 11.63660259,\n",
      "        2.77189994,  5.44316449,  8.1099637 , 10.84934964, 13.52943549,\n",
      "        2.71325545,  5.3311861 ,  7.98628154, 10.64686079, 13.40911503,\n",
      "        2.67672753,  5.27232552,  7.95042796, 10.53917465, 13.1871736 ,\n",
      "        2.60379953,  5.19016242,  7.77563715, 10.32559276, 13.04951978,\n",
      "        2.58662562,  5.08483906,  7.62327042, 10.19910026, 12.73010731,\n",
      "        2.54613662,  5.0653914 ,  7.61451735, 10.10606318, 12.55843196,\n",
      "        2.52222242,  4.9597815 ,  7.44749308,  9.92833629, 12.43269973,\n",
      "        2.83405004,  5.56999898,  8.30206203, 11.16930256, 13.91994319,\n",
      "        2.7498611 ,  5.51381497,  8.22762442, 11.01665587, 13.73985624,\n",
      "        2.71723166,  5.42569132,  8.09713311, 10.90654097, 13.52473507,\n",
      "        2.65760479,  5.30257592,  7.92831016, 10.63212318, 13.2869092 ,\n",
      "        2.61010146,  5.26175079,  7.85471363, 10.43195291, 13.04425325,\n",
      "        2.59865594,  5.12830915,  7.70815921, 10.26546226, 12.8190218 ,\n",
      "        2.55493388,  5.07454939,  7.56982899, 10.13412633, 12.59773264]), 'std_fit_time': array([0.05551687, 0.33414479, 0.16213299, 0.2478827 , 0.06248854,\n",
      "       0.07816188, 0.15699831, 0.08914776, 0.17081316, 0.33001353,\n",
      "       0.02658457, 0.0660255 , 0.23109224, 0.25064692, 0.0770318 ,\n",
      "       0.07919178, 0.06272049, 0.10399107, 0.02391561, 0.4091305 ,\n",
      "       0.0239531 , 0.05491386, 0.06890473, 0.2371475 , 0.20901137,\n",
      "       0.013089  , 0.02246828, 0.07595206, 0.02179525, 0.3139724 ,\n",
      "       0.07326139, 0.03420299, 0.09387657, 0.1460678 , 0.18482518,\n",
      "       0.08349333, 0.1705168 , 0.05890087, 0.30342015, 0.77771645,\n",
      "       0.01288177, 0.45148707, 0.21792937, 0.69202264, 0.67007849,\n",
      "       0.02286162, 0.02677385, 0.03409372, 0.03548315, 0.07007364,\n",
      "       0.02225813, 0.0286888 , 0.02298398, 0.0598601 , 0.08445684,\n",
      "       0.00526565, 0.02711303, 0.04122158, 0.03061772, 0.07921753,\n",
      "       0.01392025, 0.03734689, 0.03952723, 0.0312786 , 0.03105604,\n",
      "       0.00706513, 0.00923522, 0.00750723, 0.02299173, 0.05197198,\n",
      "       0.00393273, 0.02007612, 0.02966386, 0.01046554, 0.02792831,\n",
      "       0.00471426, 0.01282902, 0.04452597, 0.01708562, 0.01349527,\n",
      "       0.01644013, 0.02008601, 0.08016835, 0.00489759, 0.08329619,\n",
      "       0.01827817, 0.00658154, 0.02741336, 0.04405442, 0.53174782,\n",
      "       0.19680041, 0.253151  , 0.13634428, 0.47514795, 0.17051062,\n",
      "       0.15874438, 0.46531389, 0.17022978, 1.35271628, 0.26772612,\n",
      "       0.03657922, 0.04378234, 0.20150271, 0.12562061, 0.33212012,\n",
      "       0.04646162, 0.04493647, 0.27835905, 0.12879366, 0.04552543,\n",
      "       0.09652796, 0.06006372, 0.2236671 , 0.39154901, 0.15450281,\n",
      "       0.07491484, 0.04816231, 0.1136898 , 0.1314791 , 0.52873542,\n",
      "       0.05602639, 0.12353955, 0.30093361, 0.18967457, 0.46020851,\n",
      "       0.03749203, 0.14994311, 0.12799369, 0.16431858, 0.42496812,\n",
      "       0.13447246, 0.18098816, 0.12120047, 0.105577  , 2.44087563,\n",
      "       0.02745323, 0.21682219, 0.35583857, 0.40852503, 0.5289128 ,\n",
      "       0.08111981, 0.2368866 , 0.56340701, 0.21274241, 0.51861679,\n",
      "       0.06335043, 0.2073447 , 0.46898751, 0.48467566, 0.0754013 ,\n",
      "       0.01023488, 0.02682255, 0.01072748, 0.05688023, 0.02978293,\n",
      "       0.02850488, 0.02761729, 0.05169871, 0.02115672, 0.01863902,\n",
      "       0.00917991, 0.03247327, 0.02337708, 0.0439036 , 0.10743899,\n",
      "       0.01266755, 0.01444849, 0.03882658, 0.038511  , 0.0350673 ,\n",
      "       0.02290553, 0.01218073, 0.03670054, 0.02260751, 0.0279968 ,\n",
      "       0.01628159, 0.0103224 , 0.01750236, 0.07735033, 0.03660658,\n",
      "       0.00861425, 0.02007344, 0.02119957, 0.01500417, 0.03927072,\n",
      "       0.01370695, 0.04603771, 0.01966668, 0.03113273, 0.02858616,\n",
      "       0.012084  , 0.00563862, 0.02676043, 0.01254215, 0.0076725 ,\n",
      "       0.0079103 , 0.01824482, 0.01645001, 0.01142068, 0.04867175,\n",
      "       0.00930315, 0.01671465, 0.0194868 , 0.01654523, 0.03906489,\n",
      "       0.0160483 , 0.01488638, 0.01694089, 0.02026447, 0.03034421,\n",
      "       0.01164926, 0.01462187, 0.00694027, 0.00950858, 0.12170443,\n",
      "       0.00948696, 0.02934735, 0.0253208 , 0.01900317, 0.02673862,\n",
      "       0.01600877, 0.01890754, 0.01974876, 0.02932647, 0.02470449,\n",
      "       0.01939249, 0.01619363, 0.0191784 , 0.02026692, 0.09027122,\n",
      "       0.00813446, 0.02851522, 0.03054505, 0.01921385, 0.02596551,\n",
      "       0.00735699, 0.01230756, 0.02550735, 0.02666093, 0.04196359,\n",
      "       0.01422199, 0.01983413, 0.05053634, 0.01750818, 0.03287244,\n",
      "       0.01196437, 0.02998325, 0.0110177 , 0.03613067, 0.05866686,\n",
      "       0.02558756, 0.02779138, 0.01341889, 0.03471069, 0.01955242,\n",
      "       0.0110539 , 0.01336356, 0.02350219, 0.03239814, 0.05916447,\n",
      "       0.01519422, 0.01786697, 0.02219677, 0.04202912, 0.02259205,\n",
      "       0.01052918, 0.04207385, 0.0282388 , 0.02847885, 0.04252982,\n",
      "       0.01598924, 0.01346359, 0.02649891, 0.05098306, 0.02628627,\n",
      "       0.0176283 , 0.02396306, 0.06502571, 0.05692634, 0.04456218,\n",
      "       0.02246918, 0.01826246, 0.0225396 , 0.02186767, 0.0651451 ,\n",
      "       0.02434941, 0.02349065, 0.04433101, 0.01375228, 0.09565794,\n",
      "       0.03142621, 0.02590428, 0.04643964, 0.03632058, 0.04359312,\n",
      "       0.01545743, 0.02748014, 0.0435453 , 0.03048515, 0.14000203,\n",
      "       0.01795417, 0.03223321, 0.02610966, 0.04382086, 0.05742681,\n",
      "       0.00544786, 0.03956653, 0.04428058, 0.11580865, 0.03601696,\n",
      "       0.01631131, 0.01937622, 0.03717308, 0.06544498, 0.04711198,\n",
      "       0.02149888, 0.04405099, 0.03854533, 0.03194408, 0.0406802 ,\n",
      "       0.03155689, 0.04046189, 0.03919942, 0.07511373, 0.05585153,\n",
      "       0.03116757, 0.02406735, 0.07033724, 0.33688944, 0.0875413 ,\n",
      "       0.00757062, 0.05088726, 0.04624536, 0.04784402, 0.09505638,\n",
      "       0.01016079, 0.04438336, 0.02903134, 0.03897395, 0.0431224 ,\n",
      "       0.03237051, 0.04306695, 0.05040738, 0.03529721, 0.04275085,\n",
      "       0.00976118, 0.02469355, 0.04629525, 0.03989692, 0.06940076]), 'mean_score_time': array([0.0324017 , 0.03408546, 0.05492482, 0.06950941, 0.0793437 ,\n",
      "       0.02320952, 0.03557568, 0.04580216, 0.06417065, 0.07342343,\n",
      "       0.01882696, 0.03457055, 0.061133  , 0.06745777, 0.07752476,\n",
      "       0.02156186, 0.0331511 , 0.04340429, 0.05577846, 0.08482022,\n",
      "       0.02392378, 0.04188523, 0.05784078, 0.06961932, 0.07243366,\n",
      "       0.01891322, 0.03088121, 0.04291773, 0.0573597 , 0.06901612,\n",
      "       0.02351079, 0.04130454, 0.05449882, 0.05896387, 0.07857194,\n",
      "       0.02601891, 0.04379621, 0.05955443, 0.08041868, 0.11469626,\n",
      "       0.03231168, 0.04929395, 0.06308999, 0.10780969, 0.09128146,\n",
      "       0.02306504, 0.04030886, 0.05668578, 0.07505016, 0.09067192,\n",
      "       0.02306795, 0.04093947, 0.05622125, 0.0748704 , 0.09075398,\n",
      "       0.02294731, 0.03964176, 0.05625496, 0.07272248, 0.09000368,\n",
      "       0.02274346, 0.03947754, 0.05563502, 0.07270017, 0.08897591,\n",
      "       0.02288599, 0.03997841, 0.05676508, 0.0727788 , 0.08862743,\n",
      "       0.0278141 , 0.05182576, 0.07071848, 0.09206796, 0.11326942,\n",
      "       0.02829957, 0.04853225, 0.06989179, 0.09059224, 0.11180215,\n",
      "       0.0275238 , 0.04832921, 0.06922822, 0.08986092, 0.11252847,\n",
      "       0.02706857, 0.04763961, 0.06837544, 0.08863063, 0.11216078,\n",
      "       0.0326407 , 0.04793296, 0.06782522, 0.09551368, 0.11966662,\n",
      "       0.03466477, 0.08359804, 0.11672797, 0.13119087, 0.18769231,\n",
      "       0.04982285, 0.07622662, 0.11342082, 0.14526944, 0.17418132,\n",
      "       0.04754262, 0.08436446, 0.12906022, 0.16487403, 0.19876676,\n",
      "       0.04678078, 0.08513403, 0.11859179, 0.16045504, 0.1973413 ,\n",
      "       0.04744034, 0.08456335, 0.12187891, 0.15704589, 0.19589167,\n",
      "       0.04580526, 0.07887015, 0.11586533, 0.15188589, 0.19384627,\n",
      "       0.04540644, 0.07963896, 0.1149653 , 0.15481467, 0.18548841,\n",
      "       0.04397259, 0.08067951, 0.11803408, 0.15059066, 0.12953105,\n",
      "       0.02807016, 0.06628556, 0.07299047, 0.11055312, 0.12301235,\n",
      "       0.03248558, 0.06424847, 0.08377485, 0.10385504, 0.12930355,\n",
      "       0.03295441, 0.06355071, 0.1020916 , 0.10370312, 0.12660728,\n",
      "       0.0299253 , 0.0534091 , 0.07684431, 0.10013289, 0.12516174,\n",
      "       0.02931552, 0.05256128, 0.07511897, 0.09804926, 0.12091417,\n",
      "       0.02903523, 0.0515934 , 0.07408147, 0.09695039, 0.11944895,\n",
      "       0.0287426 , 0.05102782, 0.07363224, 0.09566107, 0.11760249,\n",
      "       0.02851281, 0.05031009, 0.07287321, 0.09459434, 0.11686745,\n",
      "       0.01879568, 0.03097711, 0.04298124, 0.05691886, 0.06793208,\n",
      "       0.01867361, 0.03096209, 0.04453683, 0.05560107, 0.06796479,\n",
      "       0.01872797, 0.03124437, 0.0435638 , 0.05556474, 0.06801195,\n",
      "       0.01887002, 0.03100758, 0.04322143, 0.0561101 , 0.06790862,\n",
      "       0.01878581, 0.03095665, 0.0433743 , 0.05562916, 0.0682755 ,\n",
      "       0.01873498, 0.03100953, 0.04337468, 0.05588074, 0.06830416,\n",
      "       0.01873317, 0.03104372, 0.04335976, 0.05571733, 0.0679657 ,\n",
      "       0.02351832, 0.04019728, 0.05754557, 0.07521009, 0.09205656,\n",
      "       0.02326713, 0.04080529, 0.05751615, 0.07412992, 0.09070287,\n",
      "       0.02302256, 0.03993831, 0.05674729, 0.07344184, 0.0901114 ,\n",
      "       0.02353086, 0.03991432, 0.05661545, 0.07338672, 0.09032249,\n",
      "       0.02289147, 0.03971176, 0.05695906, 0.07313719, 0.08969445,\n",
      "       0.02295737, 0.03974519, 0.05614543, 0.07271638, 0.08993707,\n",
      "       0.02295065, 0.0395154 , 0.05620251, 0.07318711, 0.08901424,\n",
      "       0.02757564, 0.04917846, 0.06969247, 0.09085412, 0.11176009,\n",
      "       0.02749186, 0.04825463, 0.06932478, 0.08971429, 0.11090536,\n",
      "       0.02702847, 0.04783907, 0.06867456, 0.08898835, 0.10995936,\n",
      "       0.02677693, 0.04718056, 0.06780457, 0.08798246, 0.10839562,\n",
      "       0.02649784, 0.04688892, 0.06720958, 0.08738604, 0.10753012,\n",
      "       0.02644567, 0.04652243, 0.06701498, 0.08820519, 0.11047535,\n",
      "       0.02731066, 0.04776874, 0.06813273, 0.08890157, 0.10909066,\n",
      "       0.03020868, 0.054175  , 0.07740664, 0.10284133, 0.12439528,\n",
      "       0.02933016, 0.05344992, 0.075142  , 0.09908915, 0.12338514,\n",
      "       0.0302938 , 0.05213265, 0.07604728, 0.10016108, 0.12259579,\n",
      "       0.02862306, 0.05578299, 0.07361479, 0.09754972, 0.1203691 ,\n",
      "       0.0281033 , 0.05244536, 0.07294235, 0.09799623, 0.12039266,\n",
      "       0.02905836, 0.04995532, 0.07241535, 0.09418168, 0.11591134,\n",
      "       0.03069944, 0.05114007, 0.07184219, 0.09452591, 0.11932645,\n",
      "       0.03142047, 0.05705776, 0.07923441, 0.10363965, 0.12598844,\n",
      "       0.02986455, 0.05437398, 0.07893724, 0.10340877, 0.12715731,\n",
      "       0.0309289 , 0.05489187, 0.07682948, 0.09980664, 0.12481747,\n",
      "       0.03045602, 0.05125299, 0.0761138 , 0.0987186 , 0.12198343,\n",
      "       0.02838945, 0.05389242, 0.07387185, 0.09614592, 0.12026396,\n",
      "       0.02855716, 0.05226312, 0.0742382 , 0.0984446 , 0.12656641,\n",
      "       0.0292419 , 0.05055943, 0.07589788, 0.09628568, 0.11712351]), 'std_score_time': array([3.77314236e-03, 3.77171412e-03, 1.18902085e-02, 5.11544072e-03,\n",
      "       2.27894616e-03, 3.84632526e-03, 1.59342169e-03, 1.76135063e-03,\n",
      "       7.89081476e-03, 2.87480103e-03, 1.96690617e-04, 2.35137542e-03,\n",
      "       1.46239965e-02, 9.33959267e-03, 1.48268109e-02, 4.64898809e-03,\n",
      "       1.74066380e-03, 2.34354398e-04, 6.36149977e-04, 1.65352235e-02,\n",
      "       1.40717941e-03, 5.28298345e-03, 1.29904032e-03, 1.41730631e-02,\n",
      "       8.90634396e-03, 2.98698286e-04, 1.82594914e-04, 1.98143655e-04,\n",
      "       3.98207351e-03, 1.40361521e-03, 2.68203279e-03, 2.79532685e-03,\n",
      "       1.39116530e-03, 1.92603955e-03, 1.19673391e-02, 4.44131152e-03,\n",
      "       4.29405178e-03, 2.09602744e-03, 6.43579380e-03, 2.30080414e-02,\n",
      "       6.65172813e-04, 7.98399728e-03, 4.33909285e-03, 1.48671479e-02,\n",
      "       1.42082787e-03, 1.54395159e-04, 1.33365838e-03, 7.02666249e-04,\n",
      "       4.11742829e-03, 2.12812827e-03, 2.59613289e-04, 1.96947102e-03,\n",
      "       4.42715504e-04, 3.47866006e-03, 2.88363083e-03, 1.61519745e-04,\n",
      "       2.85010025e-04, 4.40221596e-04, 4.60176897e-04, 1.05428790e-03,\n",
      "       9.47785075e-05, 2.31172179e-04, 1.53145101e-04, 3.02318880e-04,\n",
      "       5.48929585e-04, 2.21467448e-04, 1.25709495e-03, 1.84567428e-03,\n",
      "       7.45198810e-04, 7.98240765e-04, 9.33071023e-05, 4.53251295e-03,\n",
      "       2.60469102e-04, 4.64977407e-04, 3.34508407e-04, 1.20485532e-03,\n",
      "       3.44846015e-04, 2.58681086e-04, 3.86147212e-04, 4.98428952e-04,\n",
      "       6.92465302e-04, 4.91820039e-04, 5.14320334e-04, 3.70862901e-04,\n",
      "       2.18547310e-03, 2.13933053e-04, 1.50673601e-04, 4.11694603e-04,\n",
      "       9.34016035e-05, 4.46817593e-03, 4.12584145e-03, 9.69875604e-04,\n",
      "       1.82169619e-04, 5.44638932e-03, 9.91844905e-03, 4.57792024e-03,\n",
      "       6.30965483e-03, 9.92944942e-03, 2.39218702e-02, 4.94956999e-03,\n",
      "       6.17892201e-03, 1.00332878e-03, 3.50616424e-03, 2.09584932e-03,\n",
      "       3.15935705e-03, 1.85102806e-03, 7.23255426e-04, 1.04113063e-02,\n",
      "       3.94820355e-03, 2.45551411e-03, 1.55589838e-03, 1.77294296e-03,\n",
      "       1.88765046e-03, 5.57511478e-03, 4.27420284e-03, 1.12196214e-03,\n",
      "       3.84080129e-03, 4.55155317e-03, 4.65241848e-03, 8.05814103e-03,\n",
      "       2.92070818e-03, 1.23203406e-03, 6.27715122e-03, 1.25876177e-02,\n",
      "       6.75294652e-03, 1.48821137e-03, 3.97552094e-03, 2.66113113e-03,\n",
      "       1.17016887e-02, 1.23106859e-02, 7.13861435e-04, 4.43167421e-03,\n",
      "       2.39742781e-03, 3.82012502e-03, 2.55466859e-02, 1.17565011e-04,\n",
      "       2.05875644e-02, 3.10491473e-03, 2.32899928e-02, 6.85394247e-03,\n",
      "       2.17013251e-03, 1.30506970e-02, 2.55579084e-03, 6.93498848e-04,\n",
      "       1.68610733e-03, 4.33635614e-03, 8.37683680e-03, 1.90050040e-02,\n",
      "       1.38917893e-03, 4.50982203e-04, 8.40755188e-05, 1.73212107e-04,\n",
      "       1.91257274e-04, 1.68151430e-04, 2.39223673e-03, 1.03706151e-04,\n",
      "       3.25584502e-04, 3.85753198e-04, 2.55002802e-04, 3.29535443e-04,\n",
      "       2.78772909e-04, 2.02138611e-04, 2.09374108e-04, 5.82252157e-04,\n",
      "       8.27837956e-04, 1.27616662e-04, 2.49518884e-04, 5.15804961e-04,\n",
      "       7.63330175e-04, 3.09710877e-04, 1.19526118e-04, 1.13352868e-04,\n",
      "       3.59675225e-04, 3.92342895e-04, 6.63869101e-04, 1.12525831e-04,\n",
      "       2.68590719e-04, 2.64214716e-04, 1.99445110e-03, 5.75417941e-04,\n",
      "       5.96312273e-05, 1.32871904e-04, 2.05259610e-03, 2.77468318e-04,\n",
      "       4.31536891e-04, 7.05473122e-05, 4.23953839e-04, 3.22058034e-04,\n",
      "       5.32009220e-04, 6.16145573e-05, 3.50982034e-04, 1.61811259e-04,\n",
      "       2.35102064e-04, 6.92221357e-04, 3.06700481e-04, 1.35859065e-04,\n",
      "       2.28606774e-04, 1.39686432e-04, 4.78793556e-04, 1.50189773e-03,\n",
      "       9.68300480e-05, 1.48060095e-04, 5.29785795e-04, 2.21565781e-04,\n",
      "       6.13688081e-04, 1.75433154e-04, 1.30241277e-04, 3.53651640e-04,\n",
      "       7.94982942e-04, 3.63772921e-04, 5.15269448e-04, 1.84882538e-04,\n",
      "       3.58104852e-04, 2.10803522e-03, 1.46460936e-03, 2.80366892e-04,\n",
      "       1.31001690e-03, 5.50466573e-04, 8.09997185e-04, 2.92170567e-04,\n",
      "       1.64416232e-04, 4.23271524e-04, 6.65788629e-04, 2.17278248e-04,\n",
      "       3.86579845e-04, 4.12204683e-04, 3.82125868e-04, 6.71004260e-05,\n",
      "       2.05227877e-04, 3.19103153e-04, 2.08346869e-04, 3.64151156e-04,\n",
      "       4.94022641e-04, 3.84996727e-04, 2.22242868e-04, 2.83940469e-04,\n",
      "       1.23762770e-04, 4.05080365e-04, 8.98361100e-04, 7.66478194e-04,\n",
      "       1.98733692e-04, 3.23550355e-04, 3.46552591e-04, 8.48894833e-04,\n",
      "       6.03115664e-04, 2.22511787e-04, 4.87209813e-04, 3.54821594e-04,\n",
      "       2.89271658e-04, 2.98891725e-04, 1.89928939e-04, 3.45514132e-04,\n",
      "       4.19428995e-04, 8.68223443e-05, 4.13033236e-04, 6.28041061e-05,\n",
      "       1.37550338e-04, 5.48831076e-05, 6.05007397e-04, 6.34502948e-04,\n",
      "       4.68868428e-05, 1.75588419e-04, 5.82606598e-04, 1.55544866e-04,\n",
      "       2.83486384e-04, 7.01141980e-05, 1.44299354e-04, 5.79461367e-04,\n",
      "       4.47968160e-04, 2.45114986e-04, 2.58290607e-04, 6.21863289e-04,\n",
      "       1.05935845e-03, 2.15488059e-03, 3.71237633e-03, 1.14042775e-03,\n",
      "       1.93767745e-03, 2.75741869e-03, 3.18838677e-03, 2.81973463e-03,\n",
      "       8.21573135e-04, 2.32264828e-03, 2.13882322e-03, 3.11251818e-03,\n",
      "       2.67518502e-03, 8.60716888e-04, 2.35712465e-03, 1.63114106e-03,\n",
      "       2.64753939e-03, 3.27232919e-03, 2.14870768e-03, 2.70731227e-03,\n",
      "       3.21742445e-03, 3.25515790e-03, 3.54730953e-03, 3.21550548e-04,\n",
      "       2.76064226e-03, 2.89345502e-03, 2.67873393e-03, 3.26953424e-03,\n",
      "       1.74679868e-04, 2.91991726e-03, 1.88479832e-03, 3.11712407e-03,\n",
      "       2.15685737e-03, 1.63820393e-03, 1.24163417e-03, 2.84437526e-03,\n",
      "       3.67601846e-03, 3.45592897e-03, 4.28979104e-03, 2.41378904e-03,\n",
      "       3.16574336e-03, 2.52689142e-03, 9.42653922e-03, 1.08124398e-03,\n",
      "       3.26003745e-03, 2.41460940e-03, 3.09814906e-03, 2.45246167e-03,\n",
      "       1.23306220e-03, 2.62932895e-03, 3.38388022e-03, 3.89040005e-03,\n",
      "       2.57740234e-03, 2.02161957e-03, 2.83436683e-03, 3.06473675e-03,\n",
      "       3.27550719e-03, 2.46992538e-03, 1.62293478e-03, 1.36533374e-03,\n",
      "       2.54455443e-03, 3.38656527e-03, 2.75689726e-03, 2.18245508e-04,\n",
      "       2.29087429e-03, 2.79893840e-03, 1.39583453e-03, 2.85749784e-03,\n",
      "       7.13718489e-04, 3.19669703e-03, 2.40741530e-03, 2.50531740e-03,\n",
      "       1.16771791e-02, 1.82405469e-03, 2.44834850e-03, 3.45285558e-03,\n",
      "       3.41293491e-03, 2.11558096e-03]), 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_depth': masked_array(data=[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "                   15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "                   15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 20,\n",
      "                   20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "                   20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "                   20, 20, 20, 20, 20, 20, 25, 25, 25, 25, 25, 25, 25, 25,\n",
      "                   25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
      "                   25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "                   15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "                   15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 20, 20,\n",
      "                   20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "                   20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "                   20, 20, 20, 20, 20, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
      "                   25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
      "                   25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_samples_split': masked_array(data=[10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 20, 20, 20, 20,\n",
      "                   20, 25, 25, 25, 25, 25, 30, 30, 30, 30, 30, 35, 35, 35,\n",
      "                   35, 35, 40, 40, 40, 40, 40, 10, 10, 10, 10, 10, 15, 15,\n",
      "                   15, 15, 15, 20, 20, 20, 20, 20, 25, 25, 25, 25, 25, 30,\n",
      "                   30, 30, 30, 30, 35, 35, 35, 35, 35, 40, 40, 40, 40, 40,\n",
      "                   10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 20, 20, 20, 20,\n",
      "                   20, 25, 25, 25, 25, 25, 30, 30, 30, 30, 30, 35, 35, 35,\n",
      "                   35, 35, 40, 40, 40, 40, 40, 10, 10, 10, 10, 10, 15, 15,\n",
      "                   15, 15, 15, 20, 20, 20, 20, 20, 25, 25, 25, 25, 25, 30,\n",
      "                   30, 30, 30, 30, 35, 35, 35, 35, 35, 40, 40, 40, 40, 40,\n",
      "                   10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 20, 20, 20, 20,\n",
      "                   20, 25, 25, 25, 25, 25, 30, 30, 30, 30, 30, 35, 35, 35,\n",
      "                   35, 35, 40, 40, 40, 40, 40, 10, 10, 10, 10, 10, 15, 15,\n",
      "                   15, 15, 15, 20, 20, 20, 20, 20, 25, 25, 25, 25, 25, 30,\n",
      "                   30, 30, 30, 30, 35, 35, 35, 35, 35, 40, 40, 40, 40, 40,\n",
      "                   10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 20, 20, 20, 20,\n",
      "                   20, 25, 25, 25, 25, 25, 30, 30, 30, 30, 30, 35, 35, 35,\n",
      "                   35, 35, 40, 40, 40, 40, 40, 10, 10, 10, 10, 10, 15, 15,\n",
      "                   15, 15, 15, 20, 20, 20, 20, 20, 25, 25, 25, 25, 25, 30,\n",
      "                   30, 30, 30, 30, 35, 35, 35, 35, 35, 40, 40, 40, 40, 40,\n",
      "                   10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 20, 20, 20, 20,\n",
      "                   20, 25, 25, 25, 25, 25, 30, 30, 30, 30, 30, 35, 35, 35,\n",
      "                   35, 35, 40, 40, 40, 40, 40, 10, 10, 10, 10, 10, 15, 15,\n",
      "                   15, 15, 15, 20, 20, 20, 20, 20, 25, 25, 25, 25, 25, 30,\n",
      "                   30, 30, 30, 30, 35, 35, 35, 35, 35, 40, 40, 40, 40, 40],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_n_estimators': masked_array(data=[25, 50, 75, 100, 125, 25, 50, 75, 100, 125, 25, 50, 75,\n",
      "                   100, 125, 25, 50, 75, 100, 125, 25, 50, 75, 100, 125,\n",
      "                   25, 50, 75, 100, 125, 25, 50, 75, 100, 125, 25, 50, 75,\n",
      "                   100, 125, 25, 50, 75, 100, 125, 25, 50, 75, 100, 125,\n",
      "                   25, 50, 75, 100, 125, 25, 50, 75, 100, 125, 25, 50, 75,\n",
      "                   100, 125, 25, 50, 75, 100, 125, 25, 50, 75, 100, 125,\n",
      "                   25, 50, 75, 100, 125, 25, 50, 75, 100, 125, 25, 50, 75,\n",
      "                   100, 125, 25, 50, 75, 100, 125, 25, 50, 75, 100, 125,\n",
      "                   25, 50, 75, 100, 125, 25, 50, 75, 100, 125, 25, 50, 75,\n",
      "                   100, 125, 25, 50, 75, 100, 125, 25, 50, 75, 100, 125,\n",
      "                   25, 50, 75, 100, 125, 25, 50, 75, 100, 125, 25, 50, 75,\n",
      "                   100, 125, 25, 50, 75, 100, 125, 25, 50, 75, 100, 125,\n",
      "                   25, 50, 75, 100, 125, 25, 50, 75, 100, 125, 25, 50, 75,\n",
      "                   100, 125, 25, 50, 75, 100, 125, 25, 50, 75, 100, 125,\n",
      "                   25, 50, 75, 100, 125, 25, 50, 75, 100, 125, 25, 50, 75,\n",
      "                   100, 125, 25, 50, 75, 100, 125, 25, 50, 75, 100, 125,\n",
      "                   25, 50, 75, 100, 125, 25, 50, 75, 100, 125, 25, 50, 75,\n",
      "                   100, 125, 25, 50, 75, 100, 125, 25, 50, 75, 100, 125,\n",
      "                   25, 50, 75, 100, 125, 25, 50, 75, 100, 125, 25, 50, 75,\n",
      "                   100, 125, 25, 50, 75, 100, 125, 25, 50, 75, 100, 125,\n",
      "                   25, 50, 75, 100, 125, 25, 50, 75, 100, 125, 25, 50, 75,\n",
      "                   100, 125, 25, 50, 75, 100, 125, 25, 50, 75, 100, 125,\n",
      "                   25, 50, 75, 100, 125, 25, 50, 75, 100, 125, 25, 50, 75,\n",
      "                   100, 125, 25, 50, 75, 100, 125, 25, 50, 75, 100, 125,\n",
      "                   25, 50, 75, 100, 125, 25, 50, 75, 100, 125, 25, 50, 75,\n",
      "                   100, 125, 25, 50, 75, 100, 125, 25, 50, 75, 100, 125,\n",
      "                   25, 50, 75, 100, 125, 25, 50, 75, 100, 125, 25, 50, 75,\n",
      "                   100, 125, 25, 50, 75, 100, 125, 25, 50, 75, 100, 125],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 25}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 75}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 125}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 15, 'n_estimators': 25}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 15, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 15, 'n_estimators': 75}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 15, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 15, 'n_estimators': 125}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 20, 'n_estimators': 25}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 20, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 20, 'n_estimators': 75}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 20, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 20, 'n_estimators': 125}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 25, 'n_estimators': 25}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 25, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 25, 'n_estimators': 75}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 25, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 25, 'n_estimators': 125}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 30, 'n_estimators': 25}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 30, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 30, 'n_estimators': 75}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 30, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 30, 'n_estimators': 125}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 35, 'n_estimators': 25}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 35, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 35, 'n_estimators': 75}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 35, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 35, 'n_estimators': 125}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 40, 'n_estimators': 25}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 40, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 40, 'n_estimators': 75}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 40, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 40, 'n_estimators': 125}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 25}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 75}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 125}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 15, 'n_estimators': 25}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 15, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 15, 'n_estimators': 75}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 15, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 15, 'n_estimators': 125}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 20, 'n_estimators': 25}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 20, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 20, 'n_estimators': 75}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 20, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 20, 'n_estimators': 125}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 25, 'n_estimators': 25}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 25, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 25, 'n_estimators': 75}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 25, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 25, 'n_estimators': 125}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 30, 'n_estimators': 25}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 30, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 30, 'n_estimators': 75}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 30, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 30, 'n_estimators': 125}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 35, 'n_estimators': 25}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 35, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 35, 'n_estimators': 75}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 35, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 35, 'n_estimators': 125}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 40, 'n_estimators': 25}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 40, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 40, 'n_estimators': 75}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 40, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 40, 'n_estimators': 125}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 10, 'n_estimators': 25}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 10, 'n_estimators': 75}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 10, 'n_estimators': 125}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 15, 'n_estimators': 25}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 15, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 15, 'n_estimators': 75}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 15, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 15, 'n_estimators': 125}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 20, 'n_estimators': 25}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 20, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 20, 'n_estimators': 75}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 20, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 20, 'n_estimators': 125}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 25, 'n_estimators': 25}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 25, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 25, 'n_estimators': 75}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 25, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 25, 'n_estimators': 125}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 30, 'n_estimators': 25}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 30, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 30, 'n_estimators': 75}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 30, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 30, 'n_estimators': 125}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 35, 'n_estimators': 25}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 35, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 35, 'n_estimators': 75}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 35, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 35, 'n_estimators': 125}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 40, 'n_estimators': 25}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 40, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 40, 'n_estimators': 75}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 40, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 40, 'n_estimators': 125}, {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 10, 'n_estimators': 25}, {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 10, 'n_estimators': 75}, {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 10, 'n_estimators': 125}, {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 15, 'n_estimators': 25}, {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 15, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 15, 'n_estimators': 75}, {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 15, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 15, 'n_estimators': 125}, {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 20, 'n_estimators': 25}, {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 20, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 20, 'n_estimators': 75}, {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 20, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 20, 'n_estimators': 125}, {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 25, 'n_estimators': 25}, {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 25, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 25, 'n_estimators': 75}, {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 25, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 25, 'n_estimators': 125}, {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 30, 'n_estimators': 25}, {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 30, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 30, 'n_estimators': 75}, {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 30, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 30, 'n_estimators': 125}, {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 35, 'n_estimators': 25}, {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 35, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 35, 'n_estimators': 75}, {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 35, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 35, 'n_estimators': 125}, {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 40, 'n_estimators': 25}, {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 40, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 40, 'n_estimators': 75}, {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 40, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 40, 'n_estimators': 125}, {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 10, 'n_estimators': 25}, {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 10, 'n_estimators': 75}, {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 10, 'n_estimators': 125}, {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 15, 'n_estimators': 25}, {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 15, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 15, 'n_estimators': 75}, {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 15, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 15, 'n_estimators': 125}, {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 20, 'n_estimators': 25}, {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 20, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 20, 'n_estimators': 75}, {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 20, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 20, 'n_estimators': 125}, {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 25, 'n_estimators': 25}, {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 25, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 25, 'n_estimators': 75}, {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 25, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 25, 'n_estimators': 125}, {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 30, 'n_estimators': 25}, {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 30, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 30, 'n_estimators': 75}, {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 30, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 30, 'n_estimators': 125}, {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 35, 'n_estimators': 25}, {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 35, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 35, 'n_estimators': 75}, {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 35, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 35, 'n_estimators': 125}, {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 40, 'n_estimators': 25}, {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 40, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 40, 'n_estimators': 75}, {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 40, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 40, 'n_estimators': 125}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 25}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 75}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 125}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 15, 'n_estimators': 25}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 15, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 15, 'n_estimators': 75}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 15, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 15, 'n_estimators': 125}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 20, 'n_estimators': 25}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 20, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 20, 'n_estimators': 75}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 20, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 20, 'n_estimators': 125}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 25, 'n_estimators': 25}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 25, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 25, 'n_estimators': 75}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 25, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 25, 'n_estimators': 125}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 30, 'n_estimators': 25}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 30, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 30, 'n_estimators': 75}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 30, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 30, 'n_estimators': 125}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 35, 'n_estimators': 25}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 35, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 35, 'n_estimators': 75}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 35, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 35, 'n_estimators': 125}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 40, 'n_estimators': 25}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 40, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 40, 'n_estimators': 75}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 40, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 40, 'n_estimators': 125}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 25}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 75}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 125}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 15, 'n_estimators': 25}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 15, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 15, 'n_estimators': 75}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 15, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 15, 'n_estimators': 125}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 20, 'n_estimators': 25}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 20, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 20, 'n_estimators': 75}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 20, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 20, 'n_estimators': 125}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 25, 'n_estimators': 25}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 25, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 25, 'n_estimators': 75}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 25, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 25, 'n_estimators': 125}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 30, 'n_estimators': 25}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 30, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 30, 'n_estimators': 75}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 30, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 30, 'n_estimators': 125}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 35, 'n_estimators': 25}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 35, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 35, 'n_estimators': 75}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 35, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 35, 'n_estimators': 125}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 40, 'n_estimators': 25}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 40, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 40, 'n_estimators': 75}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 40, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 40, 'n_estimators': 125}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 10, 'n_estimators': 25}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 10, 'n_estimators': 75}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 10, 'n_estimators': 125}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 15, 'n_estimators': 25}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 15, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 15, 'n_estimators': 75}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 15, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 15, 'n_estimators': 125}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 20, 'n_estimators': 25}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 20, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 20, 'n_estimators': 75}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 20, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 20, 'n_estimators': 125}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 25, 'n_estimators': 25}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 25, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 25, 'n_estimators': 75}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 25, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 25, 'n_estimators': 125}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 30, 'n_estimators': 25}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 30, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 30, 'n_estimators': 75}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 30, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 30, 'n_estimators': 125}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 35, 'n_estimators': 25}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 35, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 35, 'n_estimators': 75}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 35, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 35, 'n_estimators': 125}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 40, 'n_estimators': 25}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 40, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 40, 'n_estimators': 75}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 40, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 40, 'n_estimators': 125}, {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 10, 'n_estimators': 25}, {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 10, 'n_estimators': 75}, {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 10, 'n_estimators': 125}, {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 15, 'n_estimators': 25}, {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 15, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 15, 'n_estimators': 75}, {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 15, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 15, 'n_estimators': 125}, {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 20, 'n_estimators': 25}, {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 20, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 20, 'n_estimators': 75}, {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 20, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 20, 'n_estimators': 125}, {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 25, 'n_estimators': 25}, {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 25, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 25, 'n_estimators': 75}, {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 25, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 25, 'n_estimators': 125}, {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 30, 'n_estimators': 25}, {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 30, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 30, 'n_estimators': 75}, {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 30, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 30, 'n_estimators': 125}, {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 35, 'n_estimators': 25}, {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 35, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 35, 'n_estimators': 75}, {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 35, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 35, 'n_estimators': 125}, {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 40, 'n_estimators': 25}, {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 40, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 40, 'n_estimators': 75}, {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 40, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 40, 'n_estimators': 125}, {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 10, 'n_estimators': 25}, {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 10, 'n_estimators': 75}, {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 10, 'n_estimators': 125}, {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 15, 'n_estimators': 25}, {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 15, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 15, 'n_estimators': 75}, {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 15, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 15, 'n_estimators': 125}, {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 20, 'n_estimators': 25}, {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 20, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 20, 'n_estimators': 75}, {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 20, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 20, 'n_estimators': 125}, {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 25, 'n_estimators': 25}, {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 25, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 25, 'n_estimators': 75}, {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 25, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 25, 'n_estimators': 125}, {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 30, 'n_estimators': 25}, {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 30, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 30, 'n_estimators': 75}, {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 30, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 30, 'n_estimators': 125}, {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 35, 'n_estimators': 25}, {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 35, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 35, 'n_estimators': 75}, {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 35, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 35, 'n_estimators': 125}, {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 40, 'n_estimators': 25}, {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 40, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 40, 'n_estimators': 75}, {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 40, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 40, 'n_estimators': 125}], 'split0_test_score': array([0.75705598, 0.75908311, 0.76001871, 0.76001871, 0.75690005,\n",
      "       0.75549665, 0.76142211, 0.75783565, 0.75970685, 0.75799158,\n",
      "       0.74567285, 0.75923905, 0.75955091, 0.75362545, 0.76048651,\n",
      "       0.75113052, 0.75830345, 0.75970685, 0.76017465, 0.76064245,\n",
      "       0.76282551, 0.75674411, 0.75612038, 0.75658818, 0.75970685,\n",
      "       0.75113052, 0.75580851, 0.76111024, 0.76157804, 0.75923905,\n",
      "       0.75487291, 0.75580851, 0.76001871, 0.75596445, 0.75955091,\n",
      "       0.79962576, 0.79884609, 0.80445969, 0.80461562, 0.80601902,\n",
      "       0.79635116, 0.80149696, 0.80321223, 0.80212069, 0.80477156,\n",
      "       0.79837829, 0.80118509, 0.80305629, 0.80243256, 0.80679869,\n",
      "       0.79619523, 0.79822236, 0.80165289, 0.80149696, 0.80336816,\n",
      "       0.80040543, 0.80087323, 0.80539529, 0.79978169, 0.80461562,\n",
      "       0.79447996, 0.80445969, 0.80040543, 0.80258849, 0.80180883,\n",
      "       0.80149696, 0.80087323, 0.80024949, 0.80399189, 0.80149696,\n",
      "       0.80960549, 0.81443942, 0.81443942, 0.82176828, 0.82114455,\n",
      "       0.81319195, 0.81584282, 0.82114455, 0.81989708, 0.81818182,\n",
      "       0.81100889, 0.81506315, 0.81584282, 0.81584282, 0.81677842,\n",
      "       0.80586309, 0.81443942, 0.81475129, 0.81911742, 0.81709029,\n",
      "       0.81069702, 0.81241229, 0.82020895, 0.81568689, 0.81631062,\n",
      "       0.80679869, 0.81225635, 0.81303602, 0.81397162, 0.81459535,\n",
      "       0.80399189, 0.80929362, 0.81584282, 0.81350382, 0.81755809,\n",
      "       0.81178855, 0.82052082, 0.81553095, 0.82348355, 0.82223608,\n",
      "       0.81506315, 0.81802588, 0.82317168, 0.82348355, 0.82285982,\n",
      "       0.81225635, 0.81802588, 0.82005302, 0.82441915, 0.82036488,\n",
      "       0.81319195, 0.82083268, 0.82208015, 0.82208015, 0.82161235,\n",
      "       0.81303602, 0.81412755, 0.81724622, 0.81880555, 0.81693435,\n",
      "       0.80991736, 0.81210042, 0.81896148, 0.81927335, 0.81584282,\n",
      "       0.80898176, 0.81443942, 0.81646655, 0.81490722, 0.81646655,\n",
      "       0.81568689, 0.81662249, 0.81974115, 0.82457508, 0.82675815,\n",
      "       0.81646655, 0.81786995, 0.82457508, 0.81911742, 0.82176828,\n",
      "       0.81693435, 0.81568689, 0.82145642, 0.82176828, 0.82161235,\n",
      "       0.81350382, 0.81974115, 0.82020895, 0.82130048, 0.82052082,\n",
      "       0.81334789, 0.81755809, 0.81849368, 0.81911742, 0.82067675,\n",
      "       0.81210042, 0.81194449, 0.81724622, 0.81755809, 0.82067675,\n",
      "       0.80523936, 0.81537502, 0.81709029, 0.81911742, 0.81521909,\n",
      "       0.75206612, 0.74894745, 0.76126618, 0.75393731, 0.75674411,\n",
      "       0.75518478, 0.75424918, 0.75565258, 0.75690005, 0.75393731,\n",
      "       0.75191018, 0.75222205, 0.75612038, 0.75955091, 0.76048651,\n",
      "       0.75471698, 0.75627631, 0.75845938, 0.76017465, 0.76001871,\n",
      "       0.75643225, 0.75986278, 0.75955091, 0.75705598, 0.76111024,\n",
      "       0.74894745, 0.75877125, 0.75767971, 0.75845938, 0.75830345,\n",
      "       0.75643225, 0.75612038, 0.75268985, 0.75814751, 0.76126618,\n",
      "       0.79447996, 0.80134103, 0.80274443, 0.80368002, 0.80024949,\n",
      "       0.79978169, 0.80149696, 0.80149696, 0.80321223, 0.80523936,\n",
      "       0.7955715 , 0.80024949, 0.80180883, 0.79993763, 0.80134103,\n",
      "       0.79775456, 0.79728676, 0.80087323, 0.80492749, 0.80258849,\n",
      "       0.79666303, 0.79837829, 0.79884609, 0.80180883, 0.80243256,\n",
      "       0.79900203, 0.79791049, 0.80040543, 0.80040543, 0.80305629,\n",
      "       0.79759863, 0.79728676, 0.79853423, 0.80258849, 0.80087323,\n",
      "       0.80773429, 0.81880555, 0.82098862, 0.82130048, 0.81880555,\n",
      "       0.81241229, 0.81365975, 0.81709029, 0.82114455, 0.81896148,\n",
      "       0.80866989, 0.81864962, 0.82270388, 0.81818182, 0.81724622,\n",
      "       0.81225635, 0.81786995, 0.81599875, 0.81599875, 0.81833775,\n",
      "       0.81147669, 0.81303602, 0.81677842, 0.81896148, 0.81927335,\n",
      "       0.81147669, 0.81210042, 0.81397162, 0.81553095, 0.82067675,\n",
      "       0.80617496, 0.81022922, 0.81911742, 0.81319195, 0.81350382,\n",
      "       0.81755809, 0.82285982, 0.82208015, 0.82254795, 0.82410728,\n",
      "       0.81537502, 0.81802588, 0.82083268, 0.82223608, 0.82644628,\n",
      "       0.81584282, 0.81646655, 0.82223608, 0.82270388, 0.82239202,\n",
      "       0.81584282, 0.81974115, 0.81880555, 0.81771402, 0.82130048,\n",
      "       0.81210042, 0.81553095, 0.81724622, 0.82020895, 0.81989708,\n",
      "       0.81475129, 0.81833775, 0.81974115, 0.81677842, 0.82005302,\n",
      "       0.80851396, 0.81350382, 0.81662249, 0.81568689, 0.82083268,\n",
      "       0.81272415, 0.82535475, 0.82239202, 0.82644628, 0.82535475,\n",
      "       0.81381569, 0.82145642, 0.82410728, 0.82675815, 0.82551068,\n",
      "       0.81397162, 0.81974115, 0.82239202, 0.82426322, 0.82036488,\n",
      "       0.81210042, 0.81958522, 0.82176828, 0.82052082, 0.81942928,\n",
      "       0.81506315, 0.81771402, 0.81849368, 0.81709029, 0.82317168,\n",
      "       0.81365975, 0.81771402, 0.81849368, 0.81693435, 0.81755809,\n",
      "       0.81584282, 0.81849368, 0.81896148, 0.81709029, 0.81911742]), 'split1_test_score': array([0.76079838, 0.76188991, 0.75830345, 0.75814751, 0.76001871,\n",
      "       0.75721191, 0.75627631, 0.75986278, 0.75908311, 0.76235771,\n",
      "       0.75393731, 0.76142211, 0.75518478, 0.76407298, 0.75986278,\n",
      "       0.76048651, 0.75066272, 0.75690005, 0.75752378, 0.76391704,\n",
      "       0.75767971, 0.75424918, 0.75268985, 0.76282551, 0.76532044,\n",
      "       0.75814751, 0.76391704, 0.75752378, 0.75845938, 0.76142211,\n",
      "       0.75783565, 0.75534071, 0.75892718, 0.76157804, 0.75970685,\n",
      "       0.80149696, 0.80492749, 0.80648682, 0.80976142, 0.80820209,\n",
      "       0.80149696, 0.80196476, 0.80290036, 0.80570716, 0.81069702,\n",
      "       0.80305629, 0.80679869, 0.80789022, 0.80866989, 0.81085295,\n",
      "       0.79978169, 0.80773429, 0.80804616, 0.80664276, 0.80913769,\n",
      "       0.79884609, 0.80165289, 0.80336816, 0.80617496, 0.80695462,\n",
      "       0.80445969, 0.80258849, 0.80913769, 0.80726649, 0.80944956,\n",
      "       0.79806643, 0.80539529, 0.80227663, 0.80929362, 0.80742242,\n",
      "       0.81147669, 0.81584282, 0.82239202, 0.81958522, 0.82192422,\n",
      "       0.81116482, 0.81646655, 0.81303602, 0.81989708, 0.81974115,\n",
      "       0.81537502, 0.81755809, 0.81771402, 0.81989708, 0.81958522,\n",
      "       0.81038516, 0.81818182, 0.81693435, 0.82317168, 0.82083268,\n",
      "       0.80944956, 0.81989708, 0.81428349, 0.81896148, 0.81958522,\n",
      "       0.81475129, 0.81755809, 0.81864962, 0.81615469, 0.81896148,\n",
      "       0.81038516, 0.81381569, 0.81599875, 0.81709029, 0.82020895,\n",
      "       0.81490722, 0.81833775, 0.82114455, 0.82005302, 0.82208015,\n",
      "       0.81334789, 0.81927335, 0.82176828, 0.82098862, 0.82239202,\n",
      "       0.81693435, 0.82098862, 0.82192422, 0.82473102, 0.82208015,\n",
      "       0.81475129, 0.82208015, 0.82161235, 0.81989708, 0.82332762,\n",
      "       0.81568689, 0.81849368, 0.82036488, 0.81989708, 0.81833775,\n",
      "       0.80789022, 0.82005302, 0.81802588, 0.81942928, 0.82036488,\n",
      "       0.81178855, 0.81537502, 0.81864962, 0.81818182, 0.82067675,\n",
      "       0.81475129, 0.82098862, 0.82176828, 0.82254795, 0.82473102,\n",
      "       0.81163262, 0.82254795, 0.82332762, 0.82457508, 0.82535475,\n",
      "       0.81553095, 0.81755809, 0.81864962, 0.82130048, 0.82488695,\n",
      "       0.81615469, 0.81755809, 0.82067675, 0.82223608, 0.82161235,\n",
      "       0.80929362, 0.81818182, 0.81958522, 0.82052082, 0.82130048,\n",
      "       0.81506315, 0.81771402, 0.81693435, 0.82176828, 0.81864962,\n",
      "       0.81225635, 0.81568689, 0.81740215, 0.82114455, 0.81771402,\n",
      "       0.75877125, 0.75814751, 0.76204584, 0.75752378, 0.75393731,\n",
      "       0.75892718, 0.75393731, 0.76095431, 0.76547638, 0.75721191,\n",
      "       0.75845938, 0.75409325, 0.76703571, 0.76188991, 0.76079838,\n",
      "       0.74863558, 0.76111024, 0.76173398, 0.76064245, 0.75643225,\n",
      "       0.75845938, 0.76111024, 0.75284578, 0.76438484, 0.75892718,\n",
      "       0.75393731, 0.75144238, 0.76235771, 0.76266958, 0.75861531,\n",
      "       0.74863558, 0.76188991, 0.75986278, 0.76188991, 0.75892718,\n",
      "       0.80305629, 0.80383596, 0.80664276, 0.80711056, 0.81007329,\n",
      "       0.79884609, 0.80336816, 0.80695462, 0.80820209, 0.80742242,\n",
      "       0.80305629, 0.80664276, 0.80913769, 0.80804616, 0.80851396,\n",
      "       0.80523936, 0.80445969, 0.80804616, 0.80586309, 0.80866989,\n",
      "       0.80102916, 0.80149696, 0.80617496, 0.80679869, 0.80976142,\n",
      "       0.80087323, 0.80352409, 0.80274443, 0.80679869, 0.80648682,\n",
      "       0.80118509, 0.80539529, 0.80555122, 0.80913769, 0.80695462,\n",
      "       0.81163262, 0.81553095, 0.82020895, 0.81833775, 0.82254795,\n",
      "       0.81194449, 0.81927335, 0.81896148, 0.81771402, 0.82301575,\n",
      "       0.81054109, 0.81786995, 0.81864962, 0.82083268, 0.81880555,\n",
      "       0.81615469, 0.82285982, 0.81740215, 0.81833775, 0.81989708,\n",
      "       0.80960549, 0.81677842, 0.81475129, 0.81802588, 0.82020895,\n",
      "       0.81599875, 0.81646655, 0.82254795, 0.81818182, 0.81880555,\n",
      "       0.81194449, 0.81428349, 0.81709029, 0.81537502, 0.81755809,\n",
      "       0.81553095, 0.82083268, 0.82363948, 0.82332762, 0.82597848,\n",
      "       0.81412755, 0.82254795, 0.81974115, 0.81974115, 0.82332762,\n",
      "       0.81646655, 0.81755809, 0.82285982, 0.82020895, 0.82410728,\n",
      "       0.81334789, 0.81989708, 0.82145642, 0.82301575, 0.82239202,\n",
      "       0.81475129, 0.81615469, 0.81989708, 0.81911742, 0.82161235,\n",
      "       0.80960549, 0.81646655, 0.81942928, 0.81974115, 0.82005302,\n",
      "       0.81521909, 0.81849368, 0.81677842, 0.81880555, 0.81693435,\n",
      "       0.81381569, 0.81802588, 0.82301575, 0.82473102, 0.82348355,\n",
      "       0.81896148, 0.82145642, 0.82114455, 0.82519881, 0.82535475,\n",
      "       0.81584282, 0.81974115, 0.82395135, 0.82519881, 0.82379542,\n",
      "       0.81334789, 0.81911742, 0.82410728, 0.82130048, 0.82114455,\n",
      "       0.81116482, 0.82098862, 0.81880555, 0.82005302, 0.82130048,\n",
      "       0.81506315, 0.82317168, 0.81989708, 0.82052082, 0.82114455,\n",
      "       0.81864962, 0.81288009, 0.82020895, 0.82114455, 0.82332762]), 'split2_test_score': array([0.76466001, 0.75764192, 0.76824704, 0.76247661, 0.76590767,\n",
      "       0.7551466 , 0.75374298, 0.76341235, 0.75904554, 0.76637555,\n",
      "       0.76450405, 0.75577043, 0.76263256, 0.76450405, 0.76216469,\n",
      "       0.75951341, 0.75842171, 0.76746725, 0.7602932 , 0.76871491,\n",
      "       0.75779788, 0.76481597, 0.76325639, 0.76076107, 0.76590767,\n",
      "       0.75826575, 0.7665315 , 0.75998129, 0.76575172, 0.76325639,\n",
      "       0.7551466 , 0.75857767, 0.7643481 , 0.76606363, 0.76294448,\n",
      "       0.79772302, 0.79865876, 0.79943855, 0.80021834, 0.80084217,\n",
      "       0.79553961, 0.79881472, 0.79756706, 0.79975047, 0.80053026,\n",
      "       0.79304429, 0.79663132, 0.80099813, 0.79912664, 0.80364941,\n",
      "       0.7922645 , 0.79600749, 0.79819089, 0.79819089, 0.79975047,\n",
      "       0.79398004, 0.8003743 , 0.79772302, 0.79756706, 0.80068621,\n",
      "       0.79304429, 0.79975047, 0.79881472, 0.8003743 , 0.79834685,\n",
      "       0.79538366, 0.79600749, 0.7974111 , 0.79943855, 0.79444791,\n",
      "       0.80739239, 0.81269495, 0.81051154, 0.81409857, 0.81846538,\n",
      "       0.80879601, 0.80926388, 0.81316282, 0.81487835, 0.81519027,\n",
      "       0.80723643, 0.81082346, 0.81503431, 0.81456644, 0.8117592 ,\n",
      "       0.80630069, 0.81253899, 0.80832813, 0.81035558, 0.81253899,\n",
      "       0.81097941, 0.8106675 , 0.80754835, 0.81051154, 0.81238303,\n",
      "       0.80505303, 0.80926388, 0.80848409, 0.81097941, 0.81082346,\n",
      "       0.80333749, 0.8077043 , 0.80598877, 0.8117592 , 0.80864005,\n",
      "       0.8147224 , 0.81363069, 0.81846538, 0.81846538, 0.81815346,\n",
      "       0.80832813, 0.81097941, 0.81893325, 0.81659389, 0.81737367,\n",
      "       0.81238303, 0.81363069, 0.81129133, 0.81659389, 0.81674984,\n",
      "       0.81674984, 0.81394261, 0.81643793, 0.81503431, 0.8169058 ,\n",
      "       0.81097941, 0.80708047, 0.81394261, 0.81160324, 0.81191516,\n",
      "       0.80458515, 0.80988771, 0.81253899, 0.81331878, 0.81222707,\n",
      "       0.80801622, 0.80848409, 0.81097941, 0.80879601, 0.80973175,\n",
      "       0.80567686, 0.81830942, 0.81768559, 0.82049283, 0.81908921,\n",
      "       0.81129133, 0.81253899, 0.81456644, 0.81628197, 0.81830942,\n",
      "       0.80910792, 0.81487835, 0.81316282, 0.81503431, 0.81238303,\n",
      "       0.81113537, 0.81768559, 0.81331878, 0.81534623, 0.8158141 ,\n",
      "       0.81222707, 0.8117592 , 0.81144729, 0.81597006, 0.81441048,\n",
      "       0.8077043 , 0.80895197, 0.81191516, 0.81425452, 0.81207112,\n",
      "       0.80630069, 0.81004367, 0.80817218, 0.81222707, 0.81331878,\n",
      "       0.7551466 , 0.76185278, 0.76247661, 0.76154086, 0.76232065,\n",
      "       0.76481597, 0.76200873, 0.76185278, 0.7602932 , 0.7643481 ,\n",
      "       0.75436681, 0.76247661, 0.76466001, 0.76154086, 0.76013724,\n",
      "       0.76122895, 0.76076107, 0.76185278, 0.7643481 , 0.76466001,\n",
      "       0.76310044, 0.76200873, 0.7654398 , 0.76044916, 0.76185278,\n",
      "       0.7602932 , 0.76294448, 0.76325639, 0.76076107, 0.76637555,\n",
      "       0.75140362, 0.75764192, 0.76200873, 0.76512789, 0.76247661,\n",
      "       0.79538366, 0.80115409, 0.79943855, 0.79975047, 0.79819089,\n",
      "       0.79647536, 0.7974111 , 0.79772302, 0.79756706, 0.79709919,\n",
      "       0.79273238, 0.79382408, 0.79787898, 0.79959451, 0.79538366,\n",
      "       0.79101684, 0.79538366, 0.7992826 , 0.79678727, 0.7963194 ,\n",
      "       0.79553961, 0.79709919, 0.7992826 , 0.79897068, 0.79491578,\n",
      "       0.79850281, 0.79491578, 0.79663132, 0.79850281, 0.79881472,\n",
      "       0.79288833, 0.79444791, 0.79834685, 0.80006238, 0.79803493,\n",
      "       0.8077043 , 0.81191516, 0.81425452, 0.81409857, 0.81425452,\n",
      "       0.81051154, 0.81097941, 0.8117592 , 0.81363069, 0.81441048,\n",
      "       0.80676856, 0.81160324, 0.8077043 , 0.81394261, 0.81253899,\n",
      "       0.80318153, 0.80302558, 0.81331878, 0.81316282, 0.81035558,\n",
      "       0.8055209 , 0.80630069, 0.80879601, 0.81019963, 0.8095758 ,\n",
      "       0.80286962, 0.81004367, 0.80926388, 0.8095758 , 0.81019963,\n",
      "       0.80630069, 0.80536494, 0.80848409, 0.81082346, 0.80817218,\n",
      "       0.80505303, 0.81893325, 0.81612601, 0.81877729, 0.81940112,\n",
      "       0.81019963, 0.81706176, 0.81643793, 0.8147224 , 0.81971304,\n",
      "       0.81144729, 0.81378665, 0.81659389, 0.81363069, 0.82018091,\n",
      "       0.81269495, 0.81456644, 0.81378665, 0.81550218, 0.81269495,\n",
      "       0.80754835, 0.81316282, 0.81207112, 0.81565814, 0.8169058 ,\n",
      "       0.80910792, 0.81222707, 0.81160324, 0.81269495, 0.8106675 ,\n",
      "       0.80754835, 0.81160324, 0.81035558, 0.80910792, 0.81129133,\n",
      "       0.80708047, 0.81129133, 0.81752963, 0.82018091, 0.81877729,\n",
      "       0.81253899, 0.81721772, 0.81597006, 0.81721772, 0.81893325,\n",
      "       0.81207112, 0.81534623, 0.8158141 , 0.81550218, 0.81924517,\n",
      "       0.8055209 , 0.81113537, 0.81378665, 0.81674984, 0.81503431,\n",
      "       0.80520898, 0.81331878, 0.81378665, 0.81409857, 0.81425452,\n",
      "       0.80380536, 0.81035558, 0.81222707, 0.80988771, 0.81269495,\n",
      "       0.8095758 , 0.80988771, 0.80879601, 0.80973175, 0.81207112]), 'split3_test_score': array([0.76575172, 0.76403618, 0.76466001, 0.76684342, 0.76512789,\n",
      "       0.76216469, 0.76871491, 0.7654398 , 0.76668746, 0.76497193,\n",
      "       0.76388022, 0.75810979, 0.76855895, 0.76154086, 0.76372427,\n",
      "       0.75764192, 0.76621959, 0.76466001, 0.76621959, 0.76793512,\n",
      "       0.76637555, 0.76388022, 0.76403618, 0.76637555, 0.76310044,\n",
      "       0.76310044, 0.76731129, 0.76169682, 0.76122895, 0.76637555,\n",
      "       0.7592015 , 0.76341235, 0.7654398 , 0.76621959, 0.7694947 ,\n",
      "       0.79756706, 0.80053026, 0.79787898, 0.80115409, 0.80286962,\n",
      "       0.79616344, 0.79429195, 0.79819089, 0.80053026, 0.801466  ,\n",
      "       0.79850281, 0.79819089, 0.79663132, 0.7974111 , 0.80193387,\n",
      "       0.79756706, 0.79694323, 0.80271366, 0.79897068, 0.80099813,\n",
      "       0.79257642, 0.79460387, 0.79959451, 0.79678727, 0.7974111 ,\n",
      "       0.79912664, 0.79725515, 0.79897068, 0.80131004, 0.79725515,\n",
      "       0.79475983, 0.79819089, 0.79725515, 0.79772302, 0.7992826 ,\n",
      "       0.81004367, 0.8158141 , 0.81051154, 0.81378665, 0.81394261,\n",
      "       0.81191516, 0.81160324, 0.8117592 , 0.81238303, 0.81737367,\n",
      "       0.80817218, 0.81394261, 0.81550218, 0.81597006, 0.81487835,\n",
      "       0.80645664, 0.80786026, 0.81097941, 0.81409857, 0.81207112,\n",
      "       0.80848409, 0.80895197, 0.8117592 , 0.80910792, 0.81082346,\n",
      "       0.8077043 , 0.80458515, 0.80739239, 0.80910792, 0.81144729,\n",
      "       0.80380536, 0.80801622, 0.80848409, 0.80848409, 0.80941984,\n",
      "       0.81269495, 0.81908921, 0.81378665, 0.8169058 , 0.82080474,\n",
      "       0.80926388, 0.81784155, 0.81425452, 0.81534623, 0.82064878,\n",
      "       0.80458515, 0.81643793, 0.81550218, 0.81659389, 0.81893325,\n",
      "       0.80832813, 0.8147224 , 0.81597006, 0.81768559, 0.81487835,\n",
      "       0.80801622, 0.81628197, 0.81113537, 0.81300686, 0.81456644,\n",
      "       0.80973175, 0.81097941, 0.81347473, 0.81269495, 0.81035558,\n",
      "       0.80645664, 0.81129133, 0.81316282, 0.81222707, 0.80895197,\n",
      "       0.80536494, 0.8179975 , 0.81893325, 0.82330006, 0.82033687,\n",
      "       0.81222707, 0.81893325, 0.81971304, 0.81768559, 0.81846538,\n",
      "       0.81737367, 0.81238303, 0.81674984, 0.8158141 , 0.81659389,\n",
      "       0.80676856, 0.81441048, 0.81908921, 0.81456644, 0.81643793,\n",
      "       0.80832813, 0.81207112, 0.81363069, 0.81752963, 0.81456644,\n",
      "       0.80941984, 0.8095758 , 0.81519027, 0.81378665, 0.81550218,\n",
      "       0.81019963, 0.81113537, 0.81035558, 0.81113537, 0.81487835,\n",
      "       0.76575172, 0.76169682, 0.76247661, 0.76278852, 0.76684342,\n",
      "       0.75935745, 0.76902682, 0.76403618, 0.76746725, 0.76731129,\n",
      "       0.75296319, 0.75842171, 0.76466001, 0.76372427, 0.76871491,\n",
      "       0.75655022, 0.75764192, 0.76731129, 0.7654398 , 0.76403618,\n",
      "       0.76013724, 0.76044916, 0.76247661, 0.76481597, 0.76419214,\n",
      "       0.76793512, 0.76200873, 0.76310044, 0.76731129, 0.76419214,\n",
      "       0.75904554, 0.76419214, 0.76512789, 0.7665315 , 0.76559576,\n",
      "       0.79507174, 0.79725515, 0.79694323, 0.80208983, 0.79647536,\n",
      "       0.79663132, 0.79647536, 0.79694323, 0.79959451, 0.80084217,\n",
      "       0.79382408, 0.80021834, 0.79912664, 0.79881472, 0.79850281,\n",
      "       0.7922645 , 0.79304429, 0.79803493, 0.80115409, 0.79943855,\n",
      "       0.79834685, 0.79772302, 0.79429195, 0.7974111 , 0.79709919,\n",
      "       0.79709919, 0.79772302, 0.79943855, 0.80068621, 0.79943855,\n",
      "       0.79273238, 0.79647536, 0.79694323, 0.79585153, 0.79850281,\n",
      "       0.80708047, 0.80973175, 0.81597006, 0.81971304, 0.81674984,\n",
      "       0.80786026, 0.81565814, 0.81082346, 0.81441048, 0.8158141 ,\n",
      "       0.81222707, 0.81316282, 0.81269495, 0.81550218, 0.81487835,\n",
      "       0.80848409, 0.81347473, 0.81160324, 0.81456644, 0.8117592 ,\n",
      "       0.80723643, 0.8095758 , 0.81113537, 0.8106675 , 0.81160324,\n",
      "       0.80567686, 0.80676856, 0.80864005, 0.80879601, 0.81097941,\n",
      "       0.80567686, 0.80692452, 0.81019963, 0.81019963, 0.8106675 ,\n",
      "       0.81129133, 0.81643793, 0.8209607 , 0.81737367, 0.82252027,\n",
      "       0.80583281, 0.8179975 , 0.81862133, 0.81752963, 0.81830942,\n",
      "       0.81113537, 0.81550218, 0.82002495, 0.81550218, 0.81737367,\n",
      "       0.81737367, 0.81207112, 0.81955708, 0.81565814, 0.81752963,\n",
      "       0.81160324, 0.81222707, 0.81425452, 0.8117592 , 0.81409857,\n",
      "       0.80723643, 0.81394261, 0.81035558, 0.81004367, 0.8147224 ,\n",
      "       0.81019963, 0.81253899, 0.8106675 , 0.81051154, 0.81347473,\n",
      "       0.81269495, 0.81409857, 0.81955708, 0.82283219, 0.82361198,\n",
      "       0.81565814, 0.81706176, 0.81659389, 0.8209607 , 0.81940112,\n",
      "       0.81129133, 0.8179975 , 0.81565814, 0.81846538, 0.81659389,\n",
      "       0.80910792, 0.81347473, 0.81300686, 0.81597006, 0.81768559,\n",
      "       0.81612601, 0.81316282, 0.81456644, 0.81253899, 0.81456644,\n",
      "       0.80926388, 0.81097941, 0.81409857, 0.81363069, 0.81363069,\n",
      "       0.8077043 , 0.81035558, 0.81160324, 0.81347473, 0.81394261]), 'split4_test_score': array([0.75077979, 0.75374298, 0.75639426, 0.75701809, 0.75655022,\n",
      "       0.75764192, 0.76013724, 0.76013724, 0.76076107, 0.75686213,\n",
      "       0.74048659, 0.75795384, 0.76216469, 0.75888958, 0.75545852,\n",
      "       0.75639426, 0.75249532, 0.76154086, 0.75826575, 0.75779788,\n",
      "       0.75592639, 0.75343107, 0.76247661, 0.75592639, 0.75998129,\n",
      "       0.75545852, 0.75701809, 0.75701809, 0.76247661, 0.75966937,\n",
      "       0.75155958, 0.7592015 , 0.76169682, 0.76107299, 0.75982533,\n",
      "       0.79600749, 0.7952277 , 0.79803493, 0.79444791, 0.79460387,\n",
      "       0.78961323, 0.79507174, 0.79507174, 0.79538366, 0.79897068,\n",
      "       0.79335621, 0.78961323, 0.79054897, 0.79709919, 0.79600749,\n",
      "       0.7963194 , 0.79444791, 0.7952277 , 0.79507174, 0.79694323,\n",
      "       0.78649407, 0.794136  , 0.79475983, 0.79054897, 0.7952277 ,\n",
      "       0.79179663, 0.78867748, 0.79366812, 0.79475983, 0.7952277 ,\n",
      "       0.78883344, 0.79398004, 0.79257642, 0.79553961, 0.79507174,\n",
      "       0.80645664, 0.81378665, 0.81051154, 0.80973175, 0.8128509 ,\n",
      "       0.80832813, 0.80895197, 0.81004367, 0.80864005, 0.81129133,\n",
      "       0.80240175, 0.80786026, 0.81129133, 0.81019963, 0.80739239,\n",
      "       0.80240175, 0.80302558, 0.8095758 , 0.8106675 , 0.80583281,\n",
      "       0.80208983, 0.80988771, 0.80879601, 0.80801622, 0.80786026,\n",
      "       0.79787898, 0.80380536, 0.80676856, 0.80645664, 0.80692452,\n",
      "       0.79725515, 0.80396132, 0.80614473, 0.80754835, 0.80567686,\n",
      "       0.80240175, 0.81144729, 0.81238303, 0.81238303, 0.81503431,\n",
      "       0.8066126 , 0.81222707, 0.80941984, 0.81612601, 0.81643793,\n",
      "       0.80895197, 0.80895197, 0.80988771, 0.8128509 , 0.81253899,\n",
      "       0.80754835, 0.80630069, 0.81269495, 0.80941984, 0.81207112,\n",
      "       0.80536494, 0.81035558, 0.80801622, 0.80817218, 0.81394261,\n",
      "       0.80193387, 0.80739239, 0.80832813, 0.81082346, 0.8128509 ,\n",
      "       0.80131004, 0.81222707, 0.80786026, 0.8117592 , 0.8077043 ,\n",
      "       0.8044292 , 0.81378665, 0.81082346, 0.8128509 , 0.81394261,\n",
      "       0.80349345, 0.81051154, 0.81409857, 0.81441048, 0.81721772,\n",
      "       0.80193387, 0.8077043 , 0.80864005, 0.81409857, 0.81347473,\n",
      "       0.80380536, 0.81534623, 0.81222707, 0.8095758 , 0.81597006,\n",
      "       0.80598877, 0.80598877, 0.80988771, 0.81160324, 0.80817218,\n",
      "       0.80053026, 0.80895197, 0.81082346, 0.81082346, 0.81129133,\n",
      "       0.80458515, 0.80708047, 0.8095758 , 0.80973175, 0.80988771,\n",
      "       0.75748596, 0.75670618, 0.75452277, 0.75499064, 0.75966937,\n",
      "       0.75779788, 0.75577043, 0.7551466 , 0.75639426, 0.75873362,\n",
      "       0.75810979, 0.75031192, 0.75639426, 0.75966937, 0.75795384,\n",
      "       0.75764192, 0.75826575, 0.75483468, 0.76403618, 0.76325639,\n",
      "       0.75733001, 0.75608235, 0.7592015 , 0.75374298, 0.76169682,\n",
      "       0.75187149, 0.75608235, 0.7562383 , 0.75592639, 0.75389894,\n",
      "       0.75452277, 0.75545852, 0.75296319, 0.7562383 , 0.75592639,\n",
      "       0.78649407, 0.79273238, 0.79288833, 0.79663132, 0.79382408,\n",
      "       0.79288833, 0.7900811 , 0.79647536, 0.79054897, 0.79366812,\n",
      "       0.79039301, 0.79242046, 0.79475983, 0.79148472, 0.79678727,\n",
      "       0.78742982, 0.78992514, 0.7952277 , 0.78945727, 0.79709919,\n",
      "       0.78789769, 0.79273238, 0.79086089, 0.7900811 , 0.79366812,\n",
      "       0.78649407, 0.79210855, 0.79242046, 0.79304429, 0.79600749,\n",
      "       0.78649407, 0.79351216, 0.79210855, 0.79164067, 0.79429195,\n",
      "       0.80396132, 0.80973175, 0.80941984, 0.8128509 , 0.81347473,\n",
      "       0.80598877, 0.80520898, 0.8106675 , 0.81207112, 0.81004367,\n",
      "       0.80364941, 0.8025577 , 0.81253899, 0.80895197, 0.80910792,\n",
      "       0.80224579, 0.80567686, 0.8077043 , 0.80941984, 0.8066126 ,\n",
      "       0.80131004, 0.80427324, 0.80708047, 0.80676856, 0.8106675 ,\n",
      "       0.80349345, 0.80302558, 0.80271366, 0.80567686, 0.80676856,\n",
      "       0.79834685, 0.80193387, 0.80131004, 0.80864005, 0.80349345,\n",
      "       0.80411728, 0.8117592 , 0.81752963, 0.81269495, 0.81628197,\n",
      "       0.80817218, 0.8095758 , 0.81129133, 0.81519027, 0.81752963,\n",
      "       0.80723643, 0.80941984, 0.8128509 , 0.81519027, 0.81331878,\n",
      "       0.80567686, 0.80692452, 0.80754835, 0.81113537, 0.80879601,\n",
      "       0.79850281, 0.81019963, 0.80708047, 0.80864005, 0.81113537,\n",
      "       0.80411728, 0.80801622, 0.81316282, 0.80926388, 0.80973175,\n",
      "       0.80318153, 0.80723643, 0.80817218, 0.80801622, 0.80926388,\n",
      "       0.8066126 , 0.81425452, 0.81768559, 0.81550218, 0.8169058 ,\n",
      "       0.80474111, 0.8158141 , 0.81519027, 0.81643793, 0.81441048,\n",
      "       0.80879601, 0.80864005, 0.81191516, 0.81721772, 0.81269495,\n",
      "       0.80349345, 0.81113537, 0.81051154, 0.81487835, 0.8128509 ,\n",
      "       0.79959451, 0.81004367, 0.81300686, 0.8158141 , 0.8128509 ,\n",
      "       0.80754835, 0.80910792, 0.81051154, 0.80988771, 0.8095758 ,\n",
      "       0.80177792, 0.80583281, 0.80786026, 0.81004367, 0.81035558]), 'mean_test_score': array([0.75980917, 0.75927882, 0.76152469, 0.76090087, 0.76090091,\n",
      "       0.75753235, 0.76005871, 0.76133756, 0.76105681, 0.76171178,\n",
      "       0.75369621, 0.75849904, 0.76161838, 0.76052658, 0.76033935,\n",
      "       0.75703332, 0.75722056, 0.762055  , 0.76049539, 0.76380148,\n",
      "       0.76012101, 0.75862411, 0.75971588, 0.76049534, 0.76280334,\n",
      "       0.75722055, 0.76211729, 0.75946604, 0.76189894, 0.76199249,\n",
      "       0.75572325, 0.75846815, 0.76208612, 0.76217974, 0.76230445,\n",
      "       0.79848406, 0.79963806, 0.8012598 , 0.80203948, 0.80250735,\n",
      "       0.79583288, 0.79832803, 0.79938846, 0.80069845, 0.8032871 ,\n",
      "       0.79726758, 0.79848384, 0.79982499, 0.80094788, 0.80384848,\n",
      "       0.79642558, 0.79867106, 0.80116626, 0.80007461, 0.80203954,\n",
      "       0.79446041, 0.79832806, 0.80016816, 0.79817199, 0.80097905,\n",
      "       0.79658144, 0.79854626, 0.80019933, 0.80125983, 0.80041762,\n",
      "       0.79570806, 0.79888939, 0.79795376, 0.80119734, 0.79954433,\n",
      "       0.80899498, 0.81451559, 0.81367321, 0.81579409, 0.81766553,\n",
      "       0.81067922, 0.81242569, 0.81382925, 0.81513912, 0.81635565,\n",
      "       0.80883885, 0.81304951, 0.81507693, 0.8152952 , 0.81407872,\n",
      "       0.80628146, 0.81120921, 0.8121138 , 0.81548215, 0.81367318,\n",
      "       0.80833998, 0.81236331, 0.8125192 , 0.81245681, 0.81339252,\n",
      "       0.80643726, 0.80949377, 0.81086614, 0.81133406, 0.81255042,\n",
      "       0.80375501, 0.80855823, 0.81049183, 0.81167715, 0.81230076,\n",
      "       0.81130297, 0.81660515, 0.81626211, 0.81825816, 0.81966175,\n",
      "       0.81052313, 0.81566945, 0.81750952, 0.81850766, 0.81994244,\n",
      "       0.81102217, 0.81560702, 0.81573169, 0.81903777, 0.81813342,\n",
      "       0.81211391, 0.8155757 , 0.81775909, 0.81682339, 0.81775905,\n",
      "       0.8106167 , 0.81326785, 0.81414106, 0.81429698, 0.81513926,\n",
      "       0.80681167, 0.81208259, 0.81426585, 0.81510796, 0.81432825,\n",
      "       0.80731064, 0.81236339, 0.81342373, 0.81317426, 0.81270627,\n",
      "       0.80918183, 0.81754094, 0.81779035, 0.82075336, 0.82097157,\n",
      "       0.81102221, 0.81648034, 0.81925615, 0.81841411, 0.82022311,\n",
      "       0.81217616, 0.81364213, 0.81573175, 0.81760315, 0.81779019,\n",
      "       0.81027356, 0.81694831, 0.81710415, 0.81660501, 0.81807105,\n",
      "       0.8098371 , 0.8131118 , 0.81460892, 0.81694823, 0.81582527,\n",
      "       0.80896359, 0.81142765, 0.81442189, 0.8156382 , 0.8156382 ,\n",
      "       0.80771624, 0.81186428, 0.8125192 , 0.81467123, 0.81420359,\n",
      "       0.75784433, 0.75747015, 0.7605576 , 0.75815622, 0.75990297,\n",
      "       0.75921665, 0.7589985 , 0.75952849, 0.76130623, 0.76030845,\n",
      "       0.75516187, 0.75550511, 0.76177407, 0.76127506, 0.76161818,\n",
      "       0.75575473, 0.75881106, 0.76083842, 0.76292823, 0.76168071,\n",
      "       0.75909186, 0.75990265, 0.75990292, 0.76008979, 0.76155583,\n",
      "       0.75659692, 0.75824984, 0.76052651, 0.76102554, 0.76027708,\n",
      "       0.75400795, 0.75906057, 0.75853049, 0.76158702, 0.76083842,\n",
      "       0.79489714, 0.79926372, 0.79973146, 0.80185244, 0.79976262,\n",
      "       0.79692456, 0.79776654, 0.79991864, 0.79982497, 0.80085425,\n",
      "       0.79511545, 0.79867103, 0.80054239, 0.79957555, 0.80010574,\n",
      "       0.79474102, 0.79601991, 0.80029292, 0.79963784, 0.8008231 ,\n",
      "       0.79589527, 0.79748597, 0.7978913 , 0.79901408, 0.79957542,\n",
      "       0.79639426, 0.79723639, 0.79832804, 0.79988749, 0.80076078,\n",
      "       0.7941797 , 0.7974235 , 0.79829682, 0.79985615, 0.79973151,\n",
      "       0.8076226 , 0.81314303, 0.8161684 , 0.81726015, 0.81716652,\n",
      "       0.80974347, 0.81295593, 0.81386039, 0.81579417, 0.8164491 ,\n",
      "       0.8083712 , 0.81276867, 0.81485835, 0.81548225, 0.81451541,\n",
      "       0.80846449, 0.81258139, 0.81320545, 0.81429712, 0.81339244,\n",
      "       0.80702991, 0.80999283, 0.81170831, 0.81292461, 0.81426577,\n",
      "       0.80790307, 0.80968096, 0.81142743, 0.81155229, 0.81348598,\n",
      "       0.80568877, 0.80774721, 0.81124029, 0.81164602, 0.81067901,\n",
      "       0.81071013, 0.81816458, 0.8200672 , 0.8189443 , 0.82165783,\n",
      "       0.81074144, 0.81704178, 0.81738489, 0.81788391, 0.8210652 ,\n",
      "       0.81242569, 0.81454666, 0.81891313, 0.8174472 , 0.81947453,\n",
      "       0.81298724, 0.81464006, 0.81623081, 0.81660509, 0.81654262,\n",
      "       0.80890122, 0.81345503, 0.81410988, 0.81507675, 0.81672983,\n",
      "       0.80896368, 0.81379804, 0.81485842, 0.81370441, 0.81504554,\n",
      "       0.80893251, 0.81267523, 0.81251923, 0.81242562, 0.8143594 ,\n",
      "       0.81058557, 0.81660501, 0.82003601, 0.82193852, 0.82162667,\n",
      "       0.81314308, 0.81860128, 0.81860121, 0.82131466, 0.82072206,\n",
      "       0.81239458, 0.81629322, 0.81794615, 0.82012946, 0.81853886,\n",
      "       0.80871412, 0.81488962, 0.81663612, 0.81788391, 0.81722893,\n",
      "       0.8094315 , 0.81504558, 0.81573184, 0.81591899, 0.81722881,\n",
      "       0.8098681 , 0.81426572, 0.81504559, 0.81417226, 0.81492081,\n",
      "       0.81071009, 0.81148998, 0.81348599, 0.814297  , 0.81576287]), 'std_test_score': array([0.00545771, 0.00354439, 0.00433557, 0.00349949, 0.00396607,\n",
      "       0.00250636, 0.00511839, 0.00272075, 0.00288287, 0.00374581,\n",
      "       0.00958593, 0.00184315, 0.00436266, 0.00399328, 0.00278786,\n",
      "       0.00327711, 0.00545768, 0.00369947, 0.00305653, 0.00417768,\n",
      "       0.00388292, 0.00480849, 0.00449699, 0.00390431, 0.00259281,\n",
      "       0.00391709, 0.00480634, 0.00188202, 0.00234777, 0.00261198,\n",
      "       0.00264394, 0.00289308, 0.00248066, 0.00378475, 0.00381011,\n",
      "       0.00189391, 0.00315631, 0.0035414 , 0.00505959, 0.00469321,\n",
      "       0.00377438, 0.00317484, 0.00317302, 0.00335511, 0.00416314,\n",
      "       0.00372569, 0.00563274, 0.00588404, 0.00430051, 0.00495889,\n",
      "       0.00244726, 0.00469592, 0.00433782, 0.00387193, 0.00410964,\n",
      "       0.00493599, 0.00326075, 0.00382415, 0.00504048, 0.00435491,\n",
      "       0.00465547, 0.00551032, 0.00502036, 0.00402199, 0.00499472,\n",
      "       0.00417943, 0.00397888, 0.00327585, 0.00490986, 0.00473124,\n",
      "       0.00182443, 0.00120827, 0.00461721, 0.00432944, 0.00368566,\n",
      "       0.00185209, 0.00318577, 0.0038263 , 0.00436299, 0.00292706,\n",
      "       0.0042867 , 0.00337826, 0.0021002 , 0.00311219, 0.00420325,\n",
      "       0.00253372, 0.00527271, 0.00323276, 0.00497435, 0.00506477,\n",
      "       0.0032508 , 0.00393451, 0.0045032 , 0.0041824 , 0.00412528,\n",
      "       0.00540406, 0.00508272, 0.00446816, 0.00343703, 0.00402824,\n",
      "       0.00415788, 0.00317289, 0.00452029, 0.00346087, 0.00558132,\n",
      "       0.00460626, 0.00346283, 0.00317498, 0.00365828, 0.00273753,\n",
      "       0.00317134, 0.00337951, 0.00506482, 0.00316999, 0.00260348,\n",
      "       0.0041    , 0.00409142, 0.00471047, 0.00472429, 0.00329872,\n",
      "       0.00359962, 0.00564561, 0.00358081, 0.00437808, 0.00417698,\n",
      "       0.00363414, 0.0040963 , 0.0043581 , 0.00442995, 0.00226308,\n",
      "       0.00310115, 0.00427926, 0.00387431, 0.00356104, 0.00349612,\n",
      "       0.00346637, 0.00243297, 0.00383572, 0.00316694, 0.00501259,\n",
      "       0.00495531, 0.00235048, 0.00372785, 0.00416722, 0.00449378,\n",
      "       0.00420047, 0.00438006, 0.0043283 , 0.00345132, 0.00298347,\n",
      "       0.00591993, 0.00340256, 0.00445452, 0.00325885, 0.00478047,\n",
      "       0.00446962, 0.00188269, 0.0035905 , 0.00466705, 0.0024786 ,\n",
      "       0.00266156, 0.00445252, 0.00382355, 0.00307677, 0.0048098 ,\n",
      "       0.00489815, 0.00333085, 0.00261198, 0.003736  , 0.00363575,\n",
      "       0.00299073, 0.00327623, 0.00392376, 0.00457268, 0.00257757,\n",
      "       0.00456464, 0.0047064 , 0.00304963, 0.00349669, 0.00446401,\n",
      "       0.00315357, 0.00580036, 0.00352074, 0.00447027, 0.00485836,\n",
      "       0.00266847, 0.00440112, 0.004588  , 0.00154908, 0.00368611,\n",
      "       0.00414537, 0.00185354, 0.00413361, 0.00211464, 0.00307297,\n",
      "       0.00235539, 0.00203906, 0.00418808, 0.00425204, 0.00168324,\n",
      "       0.00678432, 0.00418283, 0.0029639 , 0.00386963, 0.00446892,\n",
      "       0.00366509, 0.003405  , 0.00494988, 0.00393742, 0.00326435,\n",
      "       0.00524642, 0.00388553, 0.00472297, 0.00354183, 0.00556937,\n",
      "       0.00238472, 0.00460768, 0.00393767, 0.00587954, 0.00506184,\n",
      "       0.00431075, 0.00511853, 0.00485838, 0.00525211, 0.00464981,\n",
      "       0.00620891, 0.00488344, 0.00429477, 0.00601337, 0.00448902,\n",
      "       0.00440555, 0.00281733, 0.00517394, 0.00549145, 0.0059103 ,\n",
      "       0.00509545, 0.00379227, 0.0035449 , 0.00441401, 0.0036383 ,\n",
      "       0.00497184, 0.00420998, 0.00430841, 0.00595292, 0.00418219,\n",
      "       0.00244124, 0.00353688, 0.0042144 , 0.0032539 , 0.00328417,\n",
      "       0.00245769, 0.00472502, 0.00347235, 0.00324865, 0.0043594 ,\n",
      "       0.00298426, 0.00576864, 0.00523768, 0.00402319, 0.00343923,\n",
      "       0.00529338, 0.00739458, 0.00341343, 0.0029789 , 0.00499245,\n",
      "       0.00350554, 0.00451276, 0.00361088, 0.0047515 , 0.00452614,\n",
      "       0.00506058, 0.00457834, 0.00661089, 0.0046001 , 0.00533314,\n",
      "       0.00432779, 0.00421972, 0.00638061, 0.00237065, 0.00475853,\n",
      "       0.00540261, 0.00384097, 0.00281367, 0.00384054, 0.00344686,\n",
      "       0.00357561, 0.00419383, 0.00337628, 0.00282018, 0.00334656,\n",
      "       0.00339281, 0.00284709, 0.00374123, 0.00342644, 0.00381523,\n",
      "       0.00402622, 0.00489473, 0.00502711, 0.00385635, 0.00515056,\n",
      "       0.00568711, 0.00218122, 0.00440269, 0.00436902, 0.00379797,\n",
      "       0.00347563, 0.00356786, 0.00396183, 0.00400075, 0.00441945,\n",
      "       0.00390619, 0.00361356, 0.00352092, 0.00413408, 0.00411567,\n",
      "       0.00308308, 0.00487071, 0.00230067, 0.00383229, 0.00321539,\n",
      "       0.00472419, 0.00238144, 0.00344593, 0.00413306, 0.00422311,\n",
      "       0.0023937 , 0.00415088, 0.00451623, 0.00388447, 0.00372556,\n",
      "       0.00375622, 0.00374469, 0.00530959, 0.00255376, 0.00297878,\n",
      "       0.00623109, 0.00384671, 0.00243487, 0.00257726, 0.00417126,\n",
      "       0.00409557, 0.00536468, 0.00360069, 0.00412168, 0.0040219 ,\n",
      "       0.00599143, 0.00416754, 0.00514526, 0.00434281, 0.00478873]), 'rank_test_score': array([322, 326, 298, 305, 304, 339, 318, 299, 302, 292, 350, 334, 294,\n",
      "       309, 313, 343, 341, 288, 311, 281, 316, 332, 323, 312, 283, 342,\n",
      "       286, 325, 290, 289, 346, 335, 287, 285, 284, 254, 242, 218, 215,\n",
      "       213, 274, 258, 247, 226, 212, 266, 255, 237, 222, 210, 270, 251,\n",
      "       220, 233, 214, 279, 256, 231, 260, 221, 269, 253, 230, 217, 228,\n",
      "       275, 250, 261, 219, 246, 189,  97, 117,  68,  36, 174, 145, 114,\n",
      "        82,  60, 194, 132,  84,  80, 112, 208, 167, 154,  79, 118, 199,\n",
      "       150, 142, 144, 124, 207, 186, 170, 164, 140, 211, 196, 179, 158,\n",
      "       151, 165,  53,  62,  25,  14, 178,  73,  39,  23,  13, 169,  76,\n",
      "        72,  17,  27, 153,  77,  34,  50,  35, 176, 126, 110, 104,  81,\n",
      "       206, 155, 105,  83, 101, 204, 149, 123, 128, 137, 188,  38,  32,\n",
      "         7,   6, 168,  58,  16,  24,   9, 152, 119,  71,  37,  33, 180,\n",
      "        48,  46,  56,  28, 183, 131,  95,  49,  66, 191, 162,  99,  74,\n",
      "        74, 202, 156, 142,  93, 108, 338, 340, 308, 337, 319, 327, 330,\n",
      "       324, 300, 314, 348, 347, 291, 301, 295, 345, 331, 306, 282, 293,\n",
      "       328, 321, 320, 317, 297, 344, 336, 310, 303, 315, 349, 329, 333,\n",
      "       296, 306, 277, 248, 241, 216, 239, 268, 263, 234, 238, 223, 276,\n",
      "       252, 227, 244, 232, 278, 272, 229, 243, 224, 273, 264, 262, 249,\n",
      "       245, 271, 267, 257, 235, 225, 280, 265, 259, 236, 240, 203, 130,\n",
      "        64,  42,  45, 184, 134, 113,  67,  59, 198, 136,  92,  78,  98,\n",
      "       197, 139, 127, 102, 125, 205, 181, 157, 135, 106, 200, 185, 163,\n",
      "       160, 121, 209, 201, 166, 159, 175, 172,  26,  11,  18,   2, 171,\n",
      "        47,  41,  31,   5, 145,  96,  19,  40,  15, 133,  94,  63,  54,\n",
      "        57, 193, 122, 111,  85,  51, 190, 115,  91, 116,  88, 192, 138,\n",
      "       141, 147, 100, 177,  55,  12,   1,   3, 129,  20,  21,   4,   8,\n",
      "       148,  61,  29,  10,  22, 195,  90,  52,  30,  43, 187,  87,  70,\n",
      "        65,  44, 182, 107,  86, 109,  89, 173, 161, 120, 103,  69],\n",
      "      dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "print(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f313a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e270064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7ce943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fe7fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60954bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
